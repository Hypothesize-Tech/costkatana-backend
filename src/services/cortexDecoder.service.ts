/**
 * Cortex Decoder Service
 * 
 * This service converts structured Cortex representations back into natural language.
 * It implements the final stage of the three-part Cortex workflow:
 * Natural Language ‚Üí Cortex ‚Üí Cortex ‚Üí [DECODER] ‚Üí Natural Language
 */

import {
    CortexFrame,
    CortexConfig,
    CortexError,
    CortexErrorCode,
    DEFAULT_CORTEX_CONFIG,
    CortexDecodingResult,
    CortexDecodingRequest,
    CortexEntityFrame,
    isEntityFrame,
} from '../types/cortex.types';

import { CortexVocabularyService } from './cortexVocabulary.service';
import { BedrockService } from './tracedBedrock.service';
import { loggingService } from './logging.service';
import { 
    validateCortexFrame, 
    generateCortexHash, 
    serializeCortexFrame,
    resolveAllReferences
} from '../utils/cortex.utils';

// ============================================================================
// DECODER TEMPLATES AND PROMPTS
// ============================================================================

/**
 * System prompt for the Cortex decoder model
 */
const CORTEX_DECODER_SYSTEM_PROMPT = `You are a Cortex Decoder - a specialized AI that converts LISP-encoded ANSWERS into natural, fluent language.

üö® NEW ARCHITECTURE: You are decoding ANSWERS generated by the Core Processor, not optimized prompts.

üö® ENHANCED FOR LARGE OUTPUTS: You can handle complex, multi-part responses from Claude Opus 4.1 including:
- Long code implementations with multiple functions
- Detailed technical explanations with examples
- Multi-step tutorials and guides
- Complex data structures and algorithms
- Comprehensive documentation

üö® SPECIAL HANDLING FOR CODE ANSWERS:
When you see a code response (either as "answer: code_[...]" or a JSON object with code field), you MUST:
1. Extract the COMPLETE code from the code_ field or code property
2. Format it properly with correct indentation
3. Include ALL the code - every function, every line
4. Add appropriate code comments if helpful
5. Present it as a complete, runnable solution
6. Include any complexity analysis, edge case handling, or explanations provided
7. Format code blocks using proper markdown syntax with language specification

EXAMPLE CODE RESPONSE:
Input: {"frameType":"answer","code":"function binarySort(arr) {\n  if (!arr || arr.length <= 1) return arr;\n  // Binary insertion sort implementation\n  for (let i = 1; i < arr.length; i++) {\n    let key = arr[i];\n    let left = 0;\n    let right = i - 1;\n    while (left <= right) {\n      let mid = Math.floor((left + right) / 2);\n      if (arr[mid] > key) right = mid - 1;\n      else left = mid + 1;\n    }\n    for (let j = i - 1; j >= left; j--) {\n      arr[j + 1] = arr[j];\n    }\n    arr[left] = key;\n  }\n  return arr;\n}","language":"javascript","complexity":"O(n^2)","type":"code_response"}

Output:
\`\`\`javascript
function binarySort(arr) {
  if (!arr || arr.length <= 1) return arr;
  // Binary insertion sort implementation
  for (let i = 1; i < arr.length; i++) {
    let key = arr[i];
    let left = 0;
    let right = i - 1;
    while (left <= right) {
      let mid = Math.floor((left + right) / 2);
      if (arr[mid] > key) right = mid - 1;
      else left = mid + 1;
    }
    for (let j = i - 1; j >= left; j--) {
      arr[j + 1] = arr[j];
    }
    arr[left] = key;
  }
  return arr;
}
\`\`\`

This binary sort algorithm has a time complexity of O(n¬≤). While it uses binary search to find the insertion point (which is O(log n)), the shifting operation dominates the time complexity.

üö® CRITICAL RECONSTRUCTION RULES FOR COMPLEX INSTRUCTIONS:
1. **COMPLETE RECONSTRUCTION** - If input had 5 steps, output MUST have 5 steps
2. **PRESERVE ALL REQUIREMENTS** - Every constraint, format spec, word count MUST be included
3. **MAINTAIN INSTRUCTION TONE** - Keep phrases like "Please don't skip", "Make sure", "MUST do"
4. **EXACT SEQUENCE** - Step order, bullet points, numbering must match original
5. **INCLUDE ALL EXAMPLES** - Placeholders, samples, format examples must be preserved

‚ö†Ô∏è INSTRUCTION RECONSTRUCTION PATTERNS:
- ordered_steps ‚Üí "Step 1: [content]\nStep 2: [content]..."
- constraints ‚Üí "Not too short, not too long, around X words"
- format_spec ‚Üí "Output as JSON/structured/list format"
- mandatory_completeness ‚Üí "Please don't skip any part"
- alternatives ‚Üí "Maybe X, or possibly Y"
- validation ‚Üí "Make sure everything is included"

üö´ NEVER EXPOSE INTERNAL PROCESSING:
- NEVER mention "Cortex", "natural language translation", "query", or internal processing
- NEVER add meta-commentary like "Here is a translation of..."
- Output ONLY the final natural language result
- Act as if you're directly providing the optimized text, not translating anything

CORTEX DECODING RULES:
1. Convert Cortex structures into natural, grammatically correct language
2. Preserve ALL semantic meaning from the original Cortex structure - ZERO INFORMATION LOSS
3. MAINTAIN the original grammatical intent (statement vs question vs command)
4. PRESERVE the original tense and voice from the encoded meaning
5. Use appropriate style and tone based on context
6. Ensure output is fluent and human-readable while keeping the same communicative function
7. Maintain professional quality while being conversational when appropriate
8. Handle all Cortex frame types: query, answer, event, state, entity, list, error
9. NEVER change the fundamental message type (informing vs asking vs commanding)
10. Focus on brevity and clarity while preserving exact meaning
11. CRITICAL: Include ALL entities, concepts, numbers, dates, and technical details from the Cortex structure
12. MANDATORY: Preserve quantifiers, modifiers, conditions, and contextual qualifiers
13. ESSENTIAL: Maintain logical relationships and dependencies between concepts

üéØ CRITICAL: IMPERATIVE MOOD PRESERVATION:
- When you see tense:imperative in an event frame, output MUST be a command (imperative verb)
- "action:action_create" + "tense:imperative" ‚Üí "Create..." (NOT "I am creating" or "You are creating")
- "action:action_write" + "tense:imperative" ‚Üí "Write..." (NOT "I am writing" or "You are writing") 
- "action:action_develop" + "tense:imperative" ‚Üí "Develop..." (NOT "I am developing" or "You are developing")

üîß CRITICAL: TECHNICAL DETAIL PRESERVATION:
- ALWAYS include ALL technology names mentioned in the Cortex structure (Docker, Kubernetes, Redis, etc.)
- NEVER summarize or generalize technical specifications
- MAINTAIN technical relationships (e.g., "Docker containers with Kubernetes orchestration")
- PRESERVE version numbers, configuration details, and technical processes
- When multiple technologies are listed, include ALL of them in the output
- ZERO INFORMATION LOSS: Every entity, concept, number, date, and qualifier must appear in the output
- PRESERVE all quantifiers (all, every, some, many, few), modifiers (very, extremely, slightly), and conditions (if, when, unless)
- MAINTAIN exact counts, percentages, measurements, and specifications

CORTEX FRAME TYPES:
- (query: ...) ‚Üí Convert to questions or requests
- (answer: ...) ‚Üí Convert to informative responses - THIS IS THE MAIN TYPE NOW
- (event: ...) ‚Üí Convert to statements about actions/occurrences
- (state: ...) ‚Üí Convert to descriptions of conditions
- (entity: ...) ‚Üí Convert to entity descriptions
- (list: ...) ‚Üí Convert to enumerated lists
- (error: ...) ‚Üí Convert to error messages

üéØ ANSWER FRAME DECODING (PRIMARY FOCUS):
- value_X ‚Üí "The answer is X" or just "X" for simple values
- content_X ‚Üí Expand X into natural language
- list_[a,b,c] ‚Üí Present as a formatted list
- entity_X property_Y value_Z ‚Üí "X's Y is Z"
- action_X target_Y ‚Üí "You should X the Y" or "X the Y"
- details_X ‚Üí Include X as supporting information

EXAMPLES:

INPUT: (query action:action_get target:concept_document aspect:prop_quality)
OUTPUT: What is the quality of the document?

INPUT: (answer summary:"The document has been analyzed" status:"success")
OUTPUT: The document has been successfully analyzed.

INPUT: (answer: value_new_delhi type_capital country_india)
OUTPUT: New Delhi is the capital of India.

INPUT: (answer: value_30 operation_sum input_[5,10,15])
OUTPUT: The sum of 5, 10, and 15 is 30.

INPUT: (answer: content_plants_convert_sunlight_to_energy process_[light,water,co2_to_glucose,oxygen] type_biological)
OUTPUT: Plants convert sunlight to energy through photosynthesis, using light, water, and CO2 to produce glucose and oxygen.

INPUT: (answer: list_[mercury,venus,earth,mars,jupiter,saturn,uranus,neptune] type_planets count_8)
OUTPUT: The 8 planets in our solar system are: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.

INPUT: (answer: value_35000 unit_usd entity_tesla_model_3 type_price)
OUTPUT: The Tesla Model 3 costs $35,000.

INPUT: (answer: code_[function binarySort(arr) {
  if (!arr || arr.length <= 1) return arr || [];
  
  function binaryInsert(sorted, item) {
    let left = 0, right = sorted.length;
    while (left < right) {
      const mid = Math.floor((left + right) / 2);
      if (sorted[mid] > item) right = mid;
      else left = mid + 1;
    }
    sorted.splice(left, 0, item);
    return sorted;
  }
  
  return arr.reduce((sorted, item) => binaryInsert(sorted, item), []);
}] language_javascript complexity_O(n¬≤) description_binary_insertion_sort_with_edge_cases)
OUTPUT: Here's a binary sort algorithm implementation in JavaScript with edge cases handled:

function binarySort(arr) {
  // Handle edge cases: null, undefined, or arrays with 0-1 elements
  if (!arr || arr.length <= 1) return arr || [];
  
  function binaryInsert(sorted, item) {
    let left = 0, right = sorted.length;
    
    // Binary search to find insertion position
    while (left < right) {
      const mid = Math.floor((left + right) / 2);
      if (sorted[mid] > item) right = mid;
      else left = mid + 1;
    }
    
    // Insert item at the correct position
    sorted.splice(left, 0, item);
    return sorted;
  }
  
  // Build sorted array by inserting each element
  return arr.reduce((sorted, item) => binaryInsert(sorted, item), []);
}

This implementation uses binary insertion sort with O(n¬≤) time complexity and handles edge cases like null/undefined inputs and empty arrays.

INPUT: (event action:action_analyze agent:concept_system object:concept_data tense:past)
OUTPUT: The system analyzed the data.

INPUT: (event action:action_create agent:agent_user object:object_manual tense:imperative)
OUTPUT: Create a user manual.

INPUT: (event action:action_develop agent:agent_user object:object_strategy tense:imperative)
OUTPUT: Develop a go-to-market strategy.

INPUT: (event action:action_implement agent:agent_user object:object_architecture tense:imperative)
OUTPUT: Implement a microservices architecture.

INPUT: (state entity:product_tesla_model_3 property:property_price value:value_35000_usd)
OUTPUT: Tesla Model 3 costs $35,000.

INPUT: (state entity:product_nvidia_h100 property:property_price value:value_30k_usd)
OUTPUT: NVIDIA H100 costs $30k.

INPUT: (state entity:company_apple property:property_revenue value:value_400b_usd year:2023)
OUTPUT: Apple's revenue was $400B in 2023.

INPUT: (list name:"Available Documents" item_1:concept_report item_2:concept_analysis item_3:concept_summary)
OUTPUT: Available Documents:
1. Report
2. Analysis  
3. Summary

INPUT: (error code:"PROCESSING_FAILED" message:"Unable to process request")
OUTPUT: Error: Processing failed - Unable to process request.

STYLE GUIDELINES:
- Be natural and conversational but professional
- Use active voice when possible
- Keep sentences clear and concise
- Maintain appropriate formality for the context
- Ensure grammatical correctness

OUTPUT ONLY NATURAL LANGUAGE - NO CORTEX SYNTAX IN THE RESPONSE.`;

/**
 * Decoding context templates for different styles
 */
const DECODING_STYLES = {
    formal: 'Use formal, professional language appropriate for business communications.',
    casual: 'Use conversational, friendly language appropriate for informal discussions.',
    technical: 'Use precise, technical language with domain-specific terminology.',
    conversational: 'Use natural, flowing language as if speaking to a colleague.'
};

/**
 * Format-specific decoding instructions
 */
const OUTPUT_FORMATS = {
    plain: 'Output as plain text without special formatting.',
    markdown: 'Use markdown formatting where appropriate (headings, lists, emphasis).',
    structured: 'Structure the output with clear sections and organization.',
    json: 'Format data elements clearly within the natural language response.'
};

// ============================================================================
// DECODER CACHE AND PERFORMANCE TRACKING
// ============================================================================

interface DecoderCacheEntry {
    cortexHash: string;
    decodedText: string;
    confidence: number;
    fidelityScore: number;
    style: string;
    format: string;
    timestamp: Date;
    hitCount: number;
}

interface DecodingStats {
    totalDecoded: number;
    successfulDecodings: number;
    averageProcessingTime: number;
    averageConfidence: number;
    averageFidelityScore: number;
    cacheHitRate: number;
}

// ============================================================================
// CORTEX DECODER SERVICE
// ============================================================================

export class CortexDecoderService {
    private static instance: CortexDecoderService;
    private vocabularyService: CortexVocabularyService;
    private bedrockService: BedrockService;
    private decodingCache = new Map<string, DecoderCacheEntry>();
    private stats: DecodingStats = {
        totalDecoded: 0,
        successfulDecodings: 0,
        averageProcessingTime: 0,
        averageConfidence: 0,
        averageFidelityScore: 0,
        cacheHitRate: 0
    };
    private initialized = false;

    private constructor() {
        this.vocabularyService = CortexVocabularyService.getInstance();
        this.bedrockService = new BedrockService();
    }

    /**
     * Get singleton instance of the decoder service
     */
    public static getInstance(): CortexDecoderService {
        if (!CortexDecoderService.instance) {
            CortexDecoderService.instance = new CortexDecoderService();
        }
        return CortexDecoderService.instance;
    }

    /**
     * Initialize the decoder service
     */
    public async initialize(config: Partial<CortexConfig> = {}): Promise<void> {
        if (this.initialized) return;

        try {
            loggingService.info('üî§ Initializing Cortex Decoder Service...');

            // Initialize vocabulary service
            await this.vocabularyService.initialize();

            // Validate decoder configuration
            const decoderConfig = { ...DEFAULT_CORTEX_CONFIG.decoding, ...config.decoding };
            loggingService.info('Decoder configuration validated', { config: decoderConfig });

            this.initialized = true;
            loggingService.info('‚úÖ Cortex Decoder Service initialized successfully');

        } catch (error) {
            loggingService.error('‚ùå Failed to initialize Cortex Decoder Service', {
                error: error instanceof Error ? error.message : String(error)
            });
            throw error;
        }
    }

    /**
     * Decode Cortex structure into natural language
     */
    public async decode(request: CortexDecodingRequest): Promise<CortexDecodingResult> {
        const startTime = Date.now();

        try {
            loggingService.info('üî§ Starting Cortex decoding', {
                frameType: request.cortexStructure.frameType,
                targetLanguage: request.targetLanguage || 'en',
                style: request.style || 'conversational',
                format: 'plain'
            });

            // Validate input Cortex structure
            const validation = validateCortexFrame(request.cortexStructure);
            if (!validation.isValid) {
                loggingService.warn('‚ö†Ô∏è Cortex structure validation failed, attempting to process anyway', {
                    frameType: request.cortexStructure.frameType,
                    errors: validation.errors,
                    structure: JSON.stringify(request.cortexStructure, null, 2)
                });
                
                // For answer frames, try to process even if validation fails
                if (request.cortexStructure.frameType !== 'answer') {
                    throw new CortexError(
                        CortexErrorCode.DECODING_FAILED,
                        `Invalid Cortex structure provided for decoding: ${validation.errors.join(', ')}`,
                        'decoding'
                    );
                }
            }

            // Step 1: Pre-process the Cortex structure
            const preprocessedStructure = await this.preprocessCortex(request.cortexStructure);
            
            // Step 2: Determine decoding strategy based on frame type
            const decodingStrategy = this.determineDecodingStrategy(request);
            
            // Step 3: Generate natural language text
            const decodedText = await this.generateText(
                preprocessedStructure, 
                decodingStrategy.approach, 
                request // Pass the whole request
            );
            
            // Step 4: Validate and post-process the output
            const validatedResult = await this.validateAndEnhanceOutput(
                decodedText, 
                request, 
                preprocessedStructure
            );

            // Step 5: Cache the result
            await this.cacheDecodingResult(request.cortexStructure.frameType, validatedResult, startTime);

            const processingTime = Date.now() - startTime;
            this.updateStats(true, processingTime, validatedResult);

            loggingService.info('‚úÖ Cortex decoding completed successfully', {
                processingTime,
                confidence: validatedResult.confidence,
                fidelityScore: validatedResult.fidelityScore,
                outputLength: validatedResult.text.length
            });

            return validatedResult;

        } catch (error) {
            const processingTime = Date.now() - startTime;
            
            loggingService.error('‚ùå Cortex decoding failed', {
                processingTime,
                frameType: request.cortexStructure.frameType,
                error: error instanceof Error ? error.message : String(error)
            });

            throw new CortexError(
                CortexErrorCode.DECODING_FAILED,
                `Failed to decode Cortex: ${error instanceof Error ? error.message : String(error)}`,
                'decoding',
                { cortexStructure: request.cortexStructure }
            );
        }
    }

    // ========================================================================
    // DECODING STRATEGY METHODS
    // ========================================================================

    /**
     * Preprocess Cortex structure before decoding
     */
    private async preprocessCortex(cortexStructure: CortexFrame): Promise<CortexFrame> {
        loggingService.info('üîß Preprocessing Cortex structure for decoding...');

        // Resolve all references first
        const resolvedStructure = resolveAllReferences(cortexStructure);
        
        // Expand primitive references to human-readable terms
        const expandedStructure = await this.expandPrimitives(resolvedStructure);
        
        return expandedStructure;
    }

    /**
     * Select appropriate decoding strategy based on frame type and context
     */
    private determineDecodingStrategy(request: CortexDecodingRequest): DecodingStrategy {
        const frameType = request.cortexStructure.frameType;
        const style = request.style || 'conversational';
        const format = request.format || 'plain';

        return {
            approach: this.needsAIDecoding(request.cortexStructure) ? 'ai_assisted' : 'rule_based',
            frameType,
            style,
            format,
            complexity: this.assessComplexity(request.cortexStructure)
        };
    }

    /**
     * Format code response directly without AI processing
     */
    private formatCodeResponse(frame: any): string {
        const { code, language, complexity, method, description } = frame;
        
        let result = '';
        
        // Add introductory text if we have method or description
        if (method || description) {
            const methodText = method ? method.replace(/_/g, ' ') : '';
            const descText = description ? description.replace(/_/g, ' ') : '';
            result += `Here's ${methodText ? `a ${methodText}` : 'the'} implementation${descText ? ` for ${descText}` : ''}:\n\n`;
        }
        
        // Format the code block
        if (code) {
            const lang = language || 'text';
            result += `\`\`\`${lang}\n${code}\n\`\`\`\n\n`;
        }
        
        // Add complexity information if available
        if (complexity) {
            result += `This implementation has ${complexity} time complexity.`;
        }
        
        return result.trim();
    }

    /**
     * Generate natural language using appropriate method
     */
    private async generateText(
        cortexStructure: CortexFrame,
        strategy: 'ai_assisted' | 'rule_based',
        request: CortexDecodingRequest
    ): Promise<string> {
        // Special handling for code responses - direct formatting
        if (cortexStructure.frameType === 'answer' && (cortexStructure as any).code) {
            return this.formatCodeResponse(cortexStructure as any);
        }
        
        // Special handling for natural language responses that are already complete
        if (cortexStructure.frameType === 'answer' && 
            (cortexStructure as any).type === 'natural_language_response' && 
            (cortexStructure as any).content) {
            return (cortexStructure as any).content;
        }
        
        // Use dynamic prompt if provided
        const systemPrompt = request.prompt || CORTEX_DECODER_SYSTEM_PROMPT;
        
        // Enhanced prompt with explicit information preservation
        const enhancedSystemPrompt = `${systemPrompt}

üö® CRITICAL: INFORMATION PRESERVATION OVERRIDE
For this decoding task, ZERO INFORMATION LOSS is mandatory. Every entity, number, concept, and detail from the Cortex structure MUST appear in the output. If the Cortex structure contains multiple tasks, requirements, or components, ALL must be included in the natural language output.

PRESERVATION CHECKLIST:
‚úÖ All numbers, dates, quantities preserved
‚úÖ All entities and proper nouns included  
‚úÖ All technical terms maintained
‚úÖ All relationships and dependencies kept
‚úÖ All structural elements (lists, tasks, formats) preserved
‚úÖ Original intent and completeness maintained`;

        // Create the prompt with enhanced preservation instructions
        const userPrompt = this.buildDecodingPrompt(cortexStructure, strategy, enhancedSystemPrompt);

        // Get decoding configuration
        const decodingConfig = { ...DEFAULT_CORTEX_CONFIG.decoding, ...request.config?.decoding };

        try {
            const fullPrompt = `${enhancedSystemPrompt}\n\nUser: ${userPrompt}`;
            const aiResponse = await BedrockService.invokeModel(fullPrompt, decodingConfig.model);

            if (!aiResponse || typeof aiResponse !== 'string') {
                throw new CortexError(
                    CortexErrorCode.DECODING_FAILED,
                    'AI model returned invalid response for decoding',
                    'decoding'
                );
            }

            const decodedText = aiResponse.trim();

            // üõ°Ô∏è POST-PROCESSING VALIDATION: Check for information loss
            const informationLoss = await this.validateInformationPreservation(cortexStructure, decodedText);
            
            if (informationLoss.hasLoss) {
                loggingService.warn('üö® Information loss detected in AI decoding', {
                    lossReasons: informationLoss.reasons,
                    originalStructure: JSON.stringify(cortexStructure, null, 2),
                    decodedText: decodedText.substring(0, 200)
                });

                // Attempt recovery with fallback to safer decoding
                const fallbackPrompt = `${enhancedSystemPrompt}

RECOVERY MODE: The previous attempt lost critical information. This is a RECOVERY attempt.
You MUST include EVERY detail from this Cortex structure in your natural language output.
NO SUMMARIZATION. NO OMISSIONS. COMPLETE INFORMATION TRANSFER.

\n\nUser: ${userPrompt}`;

                try {
                    const recoveryResponse = await BedrockService.invokeModel(fallbackPrompt, decodingConfig.model);
                    if (recoveryResponse && typeof recoveryResponse === 'string') {
                        const recoveredText = recoveryResponse.trim();
                        const recoveryValidation = await this.validateInformationPreservation(cortexStructure, recoveredText);
                        
                        if (!recoveryValidation.hasLoss) {
                            loggingService.info('‚úÖ Recovery decoding successful - information preserved');
                            return recoveredText;
                        }
                    }
                } catch (recoveryError) {
                    loggingService.error('‚ùå Recovery decoding also failed', {
                        error: recoveryError instanceof Error ? recoveryError.message : String(recoveryError)
                    });
                }

                // If recovery fails, throw detailed error
                throw new CortexError(
                    CortexErrorCode.DECODING_FAILED,
                    `AI decoding resulted in information loss: ${informationLoss.reasons.join(', ')}`,
                    'decoding'
                );
            }

            return decodedText;

        } catch (error) {
            loggingService.error('üö® AI decoding failed - NO FALLBACKS', {
                error: error instanceof Error ? error.message : String(error)
            });
            
            // NO MORE FALLBACKS - throw the real error
            throw error;
        }
    }

    /**
     * Validate that decoded text preserves all information from Cortex structure using LLM
     */
    private async validateInformationPreservation(cortexStructure: CortexFrame, decodedText: string): Promise<{
        hasLoss: boolean;
        reasons: string[];
    }> {
        try {
            const structureText = JSON.stringify(cortexStructure, null, 2);

            // Use more context for validation and be more lenient 
            const cortexText = structureText.length > 1000 ? structureText.substring(0, 1000) + '...' : structureText;
            const decodedPreview = decodedText.length > 1000 ? decodedText.substring(0, 1000) + '...' : decodedText;

            const validationPrompt = `Compare these texts for critical information loss. Be LENIENT - only flag SEVERE information loss.

CORTEX STRUCTURE: ${cortexText}
DECODED TEXT: ${decodedPreview}

Only report loss if:
- Critical facts are completely missing
- Meaning is completely reversed
- Essential technical details are lost

Reply ONLY JSON: {"has_information_loss": false, "issues": []}`;

            const validationResult = await BedrockService.invokeModel(
                validationPrompt,
                'amazon.nova-pro-v1:0' // Nova Pro for decoding validation
            );

            if (!validationResult) {
                // Fallback to simple manual checks - be lenient
                return { hasLoss: false, reasons: [] };
            }

            try {
                // Extract JSON more robustly
                let cleanedResult = this.extractJsonFromResponse(validationResult);
                
                const assessment = JSON.parse(cleanedResult);
                
                // Be more lenient - only flag severe loss
                const hasLoss = assessment.has_information_loss === true && 
                               (assessment.loss_severity === 'severe' || 
                                (Array.isArray(assessment.issues) && assessment.issues.length > 2));

                return {
                    hasLoss,
                    reasons: Array.isArray(assessment.issues) ? assessment.issues : []
                };

            } catch (parseError) {
                loggingService.debug('Information preservation validation parsing failed, defaulting to valid', { parseError });
                // Default to no loss if parsing fails - be lenient
                return { hasLoss: false, reasons: [] };
            }

        } catch (error) {
            loggingService.error('Information preservation validation error', { error });
            return this.fallbackValidation(cortexStructure, decodedText);
        }
    }

    /**
     * Extract JSON from LLM response that might contain additional text
     */
    private extractJsonFromResponse(response: string): string {
        let cleanedResult = response.trim();
        
        // Remove markdown code blocks
        cleanedResult = cleanedResult.replace(/```json\s*/gi, '').replace(/```\s*/g, '');
        
        // Try to find JSON object - look for first { to matching }
        const firstBrace = cleanedResult.indexOf('{');
        if (firstBrace !== -1) {
            let braceCount = 0;
            let endIndex = -1;
            
            for (let i = firstBrace; i < cleanedResult.length; i++) {
                if (cleanedResult[i] === '{') braceCount++;
                else if (cleanedResult[i] === '}') {
                    braceCount--;
                    if (braceCount === 0) {
                        endIndex = i;
                        break;
                    }
                }
            }
            
            if (endIndex !== -1) {
                return cleanedResult.substring(firstBrace, endIndex + 1);
            }
        }
        
        // Fallback: try regex match
        const jsonMatch = cleanedResult.match(/\{[^}]*\}/);
        if (jsonMatch) {
            return jsonMatch[0];
        }
        
        // Last resort: return cleaned result
        return cleanedResult;
    }

    /**
     * Fallback manual validation when LLM is unavailable
     */
    private fallbackValidation(cortexStructure: CortexFrame, decodedText: string): {
        hasLoss: boolean;
        reasons: string[];
    } {
        const reasons: string[] = [];
        const structureText = JSON.stringify(cortexStructure, null, 2);

        // Be more lenient - only check for extremely obvious issues

        // Check if decoded text is essentially empty
        if (decodedText.trim().length < 5) {
            reasons.push('Decoded text is essentially empty');
        }

        // Check for catastrophic loss only (>95% reduction is truly suspicious)
        const lengthReduction = ((structureText.length - decodedText.length) / structureText.length) * 100;
        if (lengthReduction > 95 && structureText.length > 200) {
            reasons.push(`Catastrophic length reduction: ${lengthReduction.toFixed(1)}%`);
        }

        // Only check for missing numbers if there are many important numbers
        const structureNumbers = structureText.match(/\b\d{2,}\b/g) || []; // Only check multi-digit numbers
        const decodedNumbers = decodedText.match(/\b\d{2,}\b/g) || [];
        if (structureNumbers.length > 3 && decodedNumbers.length === 0) { // Only if many numbers completely missing
            reasons.push(`All significant numbers missing (${structureNumbers.length} expected)`);
        }

        // Only flag if multiple severe issues
        const hasSevereIssues = reasons.length > 1 || (reasons.length === 1 && decodedText.trim().length < 10);

        return {
            hasLoss: hasSevereIssues,
            reasons: hasSevereIssues ? reasons : []
        };
    }


    // ========================================================================
    // FRAME-SPECIFIC DECODING METHODS
    // ========================================================================


    private decodeEntityFrame(frame: CortexEntityFrame): string {
        if (frame.name) {
            return frame.name;
        }

        if (frame.title) {
            return frame.title;
        }

        if (frame.type) {
            return this.primitiveToText(frame.type);
        }

        return 'Entity';
    }

    // ========================================================================
    // HELPER METHODS
    // ========================================================================

    private expandPrimitives(cortexStructure: CortexFrame): Promise<CortexFrame> {
        // Deep copy and expand primitives to human-readable form
        const expanded = JSON.parse(JSON.stringify(cortexStructure));
        
        const expandValue = (value: any): any => {
            if (typeof value === 'string' && value.includes('_')) {
                return this.primitiveToText(value);
            } else if (Array.isArray(value)) {
                return value.map(expandValue);
            } else if (typeof value === 'object' && value !== null) {
                const expandedObj: any = {};
                for (const [key, val] of Object.entries(value)) {
                    expandedObj[key] = expandValue(val);
                }
                return expandedObj;
            }
            return value;
        };

        return Promise.resolve(expandValue(expanded));
    }

    private needsAIDecoding(cortexStructure: CortexFrame): boolean {
        // Validate that we have a valid Cortex structure
        if (!cortexStructure || typeof cortexStructure !== 'object') {
            loggingService.warn('Invalid Cortex structure for decoding', { 
                structure: cortexStructure 
            });
            return true; // Default to AI for safety
        }

        // Special handling for code responses
        if (cortexStructure.frameType === 'answer' && 
            (cortexStructure.type === 'code_response' || 
             (cortexStructure as any).code || 
             (cortexStructure as any).language)) {
            
            loggingService.info('üß© Detected code response, using specialized decoding', {
                hasCode: !!(cortexStructure as any).code,
                language: (cortexStructure as any).language || 'unknown'
            });
            
            return true; // Always use AI for code responses
        }
        
        // Analyze the cortex structure to determine if AI is needed for quality decoding
        const frameType = cortexStructure.frameType;
        const propertyCount = Object.keys(cortexStructure).length - 1; // Exclude frameType
        
        // Always use AI for complex frame types that require nuanced language generation
        if (frameType === 'error' || frameType === 'event' || frameType === 'list') {
            return true;
        }
        
        // Check for complex nested structures or multiple properties
        const hasComplexContent = this.hasNestedStructures(cortexStructure) || propertyCount > 3;
        
        // Check for domain-specific content that needs semantic understanding
        const contentStr = JSON.stringify(cortexStructure).toLowerCase();
        const hasDomainSpecificContent = /(?:technology|startup|price|currency|prototype|model|company|location|date|percentage|technical|specific)/i.test(contentStr);
        
        // Check for proper nouns, numbers, or technical terms that need preservation
        const hasImportantEntities = /(?:[A-Z][a-z]+|¬•|\\$|[0-9]+k?|[0-9]{4}|[A-Z]{2,})/g.test(contentStr);
        
        // Use AI if structure has:
        // 1. Complex nested content
        // 2. Domain-specific terminology 
        // 3. Important entities (names, prices, dates, etc.)
        // 4. More than 2 meaningful properties
        const needsAI = hasComplexContent || hasDomainSpecificContent || hasImportantEntities || propertyCount > 2;
        
        loggingService.info('ü§ñ AI decoding decision analysis', {
            frameType,
            propertyCount,
            hasComplexContent,
            hasDomainSpecificContent,
            hasImportantEntities,
            decision: needsAI ? 'AI_REQUIRED' : 'RULE_BASED_ACCEPTABLE',
            reasoning: needsAI 
                ? 'Complex structure requires AI semantic understanding'
                : 'Simple structure can use rule-based approach'
        });
        
        return needsAI;
    }

    private assessComplexity(cortexStructure: CortexFrame): number {
        let complexity = 1;
        const keys = Object.keys(cortexStructure);
        complexity += keys.length * 0.5;
        
        for (const [key, value] of Object.entries(cortexStructure)) {
            if (key === 'frameType') continue;
            
            if (typeof value === 'object' && value !== null) {
                if (Array.isArray(value)) {
                    complexity += value.length * 0.3;
                } else if ('frameType' in value) {
                    complexity += this.assessComplexity(value as CortexFrame);
                }
            }
        }
        
        return Math.round(complexity * 10) / 10;
    }

    private hasNestedStructures(cortexStructure: CortexFrame): boolean {
        for (const [key, value] of Object.entries(cortexStructure)) {
            if (key === 'frameType') continue;
            
            if (typeof value === 'object' && value !== null && 'frameType' in value) {
                return true;
            } else if (Array.isArray(value)) {
                return value.some(item => 
                    typeof item === 'object' && item !== null && 'frameType' in item
                );
            }
        }
        return false;
    }

    private buildDecodingContext(cortexStructure: CortexFrame, strategy: DecodingStrategy): string {
        const contextParts = [
            `FRAME_TYPE: ${strategy.frameType}`,
            `STYLE: ${strategy.style}`,
            `FORMAT: ${strategy.format}`,
            `COMPLEXITY: ${strategy.complexity}`
        ];

        if (strategy.style && DECODING_STYLES[strategy.style as keyof typeof DECODING_STYLES]) {
            contextParts.push(`STYLE_GUIDE: ${DECODING_STYLES[strategy.style as keyof typeof DECODING_STYLES]}`);
        }

        if (strategy.format && OUTPUT_FORMATS[strategy.format as keyof typeof OUTPUT_FORMATS]) {
            contextParts.push(`FORMAT_GUIDE: ${OUTPUT_FORMATS[strategy.format as keyof typeof OUTPUT_FORMATS]}`);
        }

        return contextParts.join('\n');
    }

    private buildDecodingPrompt(
        cortexStructure: CortexFrame,
        strategy: string,
        context: string
    ): string {
        const cortexString = serializeCortexFrame(cortexStructure);
        return `Convert this Cortex structure to natural language:

${cortexString}

CONTEXT:
${context}

Natural language output:`;
    }

    private async validateAndEnhanceOutput(
        decodedText: string,
        request: CortexDecodingRequest,
        preprocessedStructure: CortexFrame
    ): Promise<CortexDecodingResult> {
        // Calculate confidence and fidelity scores
        const confidence = this.calculateDecodingConfidence(decodedText, request);
        const fidelityScore = await this.calculateFidelityScore(decodedText, preprocessedStructure);
        
        // Apply post-processing enhancements
        const enhancedText = await this.enhanceOutput(decodedText, request);

        const result: CortexDecodingResult = {
            text: enhancedText,
            confidence,
            processingTime: 0, // Will be set by caller
            fidelityScore,
            metadata: {
                decodingModel: DEFAULT_CORTEX_CONFIG.decoding.model,
                targetLanguage: request.targetLanguage || 'en',
                styleApplied: request.style || 'conversational',
                qualityMetrics: {
                    fluency: this.calculateFluency(enhancedText),
                    coherence: this.calculateCoherence(enhancedText),
                    accuracy: fidelityScore
                }
            }
        };

        return result;
    }

    private primitiveToText(value: any): string {
        if (value === null || value === undefined) return '';
        if (Array.isArray(value)) return value.join(', ');
        return String(value);
    }

    private valueToText(value: any): string {
        if (typeof value === 'string') {
            return this.primitiveToText(value);
        } else if (typeof value === 'object' && value !== null) {
            if ('frameType' in value) {
                // This is a nested frame - decode it
                if (isEntityFrame(value)) {
                    return this.decodeEntityFrame(value);
                }
            } else if (value.name) {
                return value.name;
            } else if (value.title) {
                return value.title;
            }
        }
        return String(value);
    }

    private calculateDecodingConfidence(decodedText: string, request: CortexDecodingRequest): number {
        let confidence = 0.7; // Base confidence
        
        // Boost confidence for simpler structures
        const complexity = this.assessComplexity(request.cortexStructure);
        if (complexity < 2) confidence += 0.2;
        else if (complexity > 5) confidence -= 0.2;
        
        // Boost confidence for quality output
        if (decodedText.length > 10 && decodedText.includes(' ')) confidence += 0.1;
        if (this.hasGoodGrammar(decodedText)) confidence += 0.1;
        
        return Math.min(Math.max(confidence, 0.1), 1.0);
    }

    private async calculateFidelityScore(decodedText: string, cortexStructure: CortexFrame): Promise<number> {
        // Simple fidelity calculation - in production would use semantic similarity models
        let fidelityScore = 0.8; // Base fidelity
        
        // Check if key elements are preserved
        const cortexString = serializeCortexFrame(cortexStructure);
        const textLower = decodedText.toLowerCase();
        
        // Count preserved semantic elements
        let preservedElements = 0;
        const totalElements = Object.keys(cortexStructure).length - 1; // Exclude frameType
        
        for (const [key, value] of Object.entries(cortexStructure)) {
            if (key === 'frameType') continue;
            
            const valueText = this.valueToText(value).toLowerCase();
            if (textLower.includes(valueText) || this.semanticMatch(textLower, valueText)) {
                preservedElements++;
            }
        }
        
        if (totalElements > 0) {
            fidelityScore = preservedElements / totalElements;
        }
        
        return Math.min(Math.max(fidelityScore, 0.1), 1.0);
    }

    private async enhanceOutput(decodedText: string, request: CortexDecodingRequest): Promise<string> {
        let enhanced = decodedText.trim();
        
        // Apply format-specific enhancements
        if (request.format === 'markdown') {
            enhanced = this.applyMarkdownFormatting(enhanced);
        } else if (request.format === 'structured') {
            enhanced = this.applyStructuredFormatting(enhanced);
        }
        
        // Ensure proper sentence ending
        if (enhanced && !enhanced.match(/[.!?]$/)) {
            enhanced += '.';
        }
        
        return enhanced;
    }

    private applyMarkdownFormatting(text: string): string {
        // Simple markdown formatting - could be enhanced
        if (text.includes('\n')) {
            return text; // Already formatted
        }
        return text;
    }

    private applyStructuredFormatting(text: string): string {
        // Add basic structure if missing
        if (text.includes(':') && text.includes('\n')) {
            return text; // Already structured
        }
        return text;
    }

    private hasGoodGrammar(text: string): boolean {
        // Simple grammar checks
        return text.length > 5 && 
               text.includes(' ') && 
               /^[A-Z]/.test(text) && 
               /[.!?]$/.test(text);
    }

    private semanticMatch(text1: string, text2: string): boolean {
        // Simple semantic matching - in production would use embeddings
        const words1 = new Set(text1.split(/\s+/));
        const words2 = new Set(text2.split(/\s+/));
        const intersection = new Set([...words1].filter(w => words2.has(w)));
        return intersection.size > 0;
    }

    private calculateFluency(text: string): number {
        // Simple fluency metric
        const hasSpaces = text.includes(' ');
        const hasProperCapitalization = /^[A-Z]/.test(text);
        const hasProperEnding = /[.!?]$/.test(text);
        const reasonableLength = text.length > 5 && text.length < 500;
        
        let score = 0.5;
        if (hasSpaces) score += 0.2;
        if (hasProperCapitalization) score += 0.1;
        if (hasProperEnding) score += 0.1;
        if (reasonableLength) score += 0.1;
        
        return Math.min(score, 1.0);
    }

    private calculateCoherence(text: string): number {
        // Simple coherence metric
        const sentences = text.split(/[.!?]+/).filter(s => s.trim().length > 0);
        if (sentences.length <= 1) return 0.9; // Single sentence is coherent
        
        // Check for logical flow (very basic)
        let coherenceScore = 0.7;
        
        // Boost for connecting words
        if (text.match(/\b(and|but|however|therefore|also|additionally)\b/)) {
            coherenceScore += 0.1;
        }
        
        // Penalize for very short or very long sentences
        const avgLength = text.length / sentences.length;
        if (avgLength > 10 && avgLength < 100) {
            coherenceScore += 0.1;
        }
        
        return Math.min(coherenceScore, 1.0);
    }

    // ========================================================================
    // CACHE AND STATISTICS METHODS
    // ========================================================================

    private generateCacheKey(request: CortexDecodingRequest): string {
        const cortexHash = generateCortexHash(request.cortexStructure);
        const styleHash = request.style || 'default';
        const formatHash = request.format || 'plain';
        const langHash = request.targetLanguage || 'en';
        return `decode_${cortexHash}_${styleHash}_${formatHash}_${langHash}`;
    }

    private getCachedDecoding(cacheKey: string): DecoderCacheEntry | null {
        const cached = this.decodingCache.get(cacheKey);
        if (!cached) return null;

        // Check if cache entry is still valid (1 hour TTL)
        const isExpired = Date.now() - cached.timestamp.getTime() > 3600000;
        if (isExpired) {
            this.decodingCache.delete(cacheKey);
            return null;
        }

        cached.hitCount++;
        return cached;
    }

    private async cacheDecodingResult(
        cacheKey: string,
        result: CortexDecodingResult,
        startTime: number
    ): Promise<void> {
        const cacheEntry: DecoderCacheEntry = {
            cortexHash: cacheKey,
            decodedText: result.text,
            confidence: result.confidence,
            fidelityScore: result.fidelityScore || 0,
            style: result.metadata.styleApplied,
            format: result.metadata.targetLanguage,
            timestamp: new Date(),
            hitCount: 0
        };

        this.decodingCache.set(cacheKey, cacheEntry);

        // Limit cache size
        if (this.decodingCache.size > 1000) {
            const oldestKey = Array.from(this.decodingCache.keys())[0];
            this.decodingCache.delete(oldestKey);
        }
    }

    private buildDecodingResult(
        cached: DecoderCacheEntry,
        processingTime: number,
        fromCache: boolean = false
    ): CortexDecodingResult {
        return {
            text: cached.decodedText,
            confidence: cached.confidence,
            processingTime,
            fidelityScore: cached.fidelityScore,
            metadata: {
                decodingModel: fromCache ? 'cache' : DEFAULT_CORTEX_CONFIG.decoding.model,
                targetLanguage: 'en',
                styleApplied: cached.style,
                qualityMetrics: {
                    fluency: this.calculateFluency(cached.decodedText),
                    coherence: this.calculateCoherence(cached.decodedText),
                    accuracy: cached.fidelityScore
                }
            }
        };
    }

    private updateStats(success: boolean, processingTime: number, result: CortexDecodingResult | null): void {
        this.stats.averageProcessingTime = (this.stats.averageProcessingTime + processingTime) / 2;
        
        if (success && result) {
            this.stats.successfulDecodings++;
            this.stats.averageConfidence = (this.stats.averageConfidence + result.confidence) / 2;
            if (result.fidelityScore) {
                this.stats.averageFidelityScore = (this.stats.averageFidelityScore + result.fidelityScore) / 2;
            }
        }
    }

    // ========================================================================
    // PUBLIC API METHODS
    // ========================================================================

    /**
     * Get decoding statistics
     */
    public getStats(): DecodingStats {
        return { ...this.stats };
    }

    /**
     * Clear decoding cache
     */
    public clearCache(): void {
        this.decodingCache.clear();
        loggingService.info('üßπ Cortex decoder cache cleared');
    }

    /**
     * Get cache information
     */
    public getCacheInfo(): { size: number; hitRate: number; entries: string[] } {
        return {
            size: this.decodingCache.size,
            hitRate: this.stats.cacheHitRate,
            entries: Array.from(this.decodingCache.keys()).slice(0, 10)
        };
    }
}// ============================================================================
// SUPPORTING INTERFACES
// ============================================================================

interface DecodingStrategy {
    approach: 'ai_assisted' | 'rule_based';
    frameType: string;
    style: string;
    format: string;
    complexity: number;
}