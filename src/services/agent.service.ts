import { ChatBedrockConverse } from "@langchain/aws";
import { AgentExecutor, createReactAgent } from "langchain/agents";
import { Tool } from "@langchain/core/tools";
import { ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate } from "@langchain/core/prompts";
import { BaseCallbackHandler } from "@langchain/core/callbacks/base";
import { StateGraph, Annotation } from "@langchain/langgraph";
import { BaseMessage, HumanMessage, SystemMessage } from "@langchain/core/messages";
import { KnowledgeBaseTool } from "../tools/knowledgeBase.tool";
import { MongoDbReaderTool } from "../tools/mongoDbReader.tool";
import { ProjectManagerTool } from "../tools/projectManager.tool";
import { ModelSelectorTool } from "../tools/modelSelector.tool";
import { AnalyticsManagerTool } from "../tools/analyticsManager.tool";
import { OptimizationManagerTool } from "../tools/optimizationManager.tool";
import { WebSearchTool } from "../tools/webSearch.tool";
import { vectorStoreService } from "./vectorStore.service";
import { RetryWithBackoff, RetryConfigs } from "../utils/retryWithBackoff";
import { loggingService } from "./logging.service";
import { buildSystemPrompt, getCompressedPrompt } from "../config/agent-prompt-template";
import { ResponseFormattersService } from "./response-formatters.service";
import { VercelToolsService } from "./vercelTools.service";
import { VercelConnection } from "../models/VercelConnection";
import { multiLlmOrchestratorService } from "./multiLlmOrchestrator.service";
import crypto from 'crypto';

export interface AgentQuery {
    userId: string;
    query: string;
    context?: {
        projectId?: string;
        conversationId?: string;
        previousMessages?: Array<{ role: string; content: string }>;
        isProjectWizard?: boolean;
        projectType?: string;
        wizardState?: any;
        previousResponses?: any;
        [key: string]: any; // Allow additional context properties
    };
    callbacks?: BaseCallbackHandler[]; // Optional callbacks for activity streaming
}

export interface AgentResponse {
    success: boolean;
    response?: string;
    error?: string;
    metadata?: {
        tokensUsed?: number;
        sources?: string[];
        executionTime?: number;
        errorType?: string;
        knowledgeEnhanced?: boolean;
        knowledgeContextLength?: number;
        fromCache?: boolean;
        langchainEnhanced?: boolean;
    };
    thinking?: {
        title: string;
        steps: Array<{
            step: number;
            description: string;
            reasoning: string;
            outcome?: string;
        }>;
        summary?: string;
    };
}

// Response cache interface
interface CachedResponse {
    response: AgentResponse;
    timestamp: number;
    hits: number;
}

// Tool factory type
type ToolFactory = () => Tool;

export class AgentService {
    private agentExecutor?: AgentExecutor;
    private initialized = false;
    private model: ChatBedrockConverse;
    private tools: Tool[];
    private circuitBreaker: <T>(fn: () => Promise<T>) => Promise<T>;
    private retryExecutor: <T>(fn: () => Promise<T>) => Promise<any>;
    
    // Optimization additions
    private toolInstances: Map<string, Tool> = new Map();
    private toolFactories: Map<string, ToolFactory> = new Map();
    private responseCache: Map<string, CachedResponse> = new Map();
    private userContextCache: Map<string, { context: string; timestamp: number }> = new Map();
    
    // Langchain Integration
    private langchainGraph?: StateGraph<any>;
    private langchainAgents: Map<string, ChatBedrockConverse> = new Map();
    private isLangchainEnabled = false;
    
    // Cache configuration
    private readonly RESPONSE_CACHE_TTL = 5 * 60 * 1000; // 5 minutes
    private readonly USER_CONTEXT_CACHE_TTL = 10 * 60 * 1000; // 10 minutes
    private readonly MAX_CACHE_SIZE = 1000;
    
    // Performance metrics
    private metrics = {
        cacheHits: 0,
        cacheMisses: 0,
        toolsLoaded: 0,
        avgResponseTime: 0,
        totalRequests: 0
    };

    constructor() {
        const defaultModel = process.env.AWS_BEDROCK_MODEL_ID || 'amazon.nova-pro-v1:0';
        const isMasterAgent = process.env.AGENT_TYPE === 'master';
        const selectedModel = isMasterAgent ? 'anthropic.claude-3-5-sonnet-20240620-v1:0' : defaultModel;
        
        this.model = new ChatBedrockConverse({
            region: process.env.AWS_BEDROCK_REGION || 'us-east-1',
            model: selectedModel,
            credentials: {
                accessKeyId: process.env.AWS_ACCESS_KEY_ID!,
                secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY!,
            },
            temperature: isMasterAgent ? 0.1 : 0.3, // Lower temp for master agent, slightly higher for Nova Pro
            maxTokens: isMasterAgent ? 8000 : 5000, // More tokens for complex tasks
        });

        loggingService.info(`ü§ñ Initialized ${isMasterAgent ? 'Master' : 'Standard'} Agent`);

        // Initialize tool factories for lazy loading
        this.initializeToolFactories();
        
        // Initialize empty tools array - will be populated lazily
        this.tools = [];

        // Initialize retry mechanism with circuit breaker
        this.circuitBreaker = RetryWithBackoff.createCircuitBreaker(5, 60000); // 5 failures, 1 min reset
        this.retryExecutor = RetryWithBackoff.createBedrockRetry({
            ...RetryConfigs.bedrock,
            onRetry: (error: Error, attempt: number) => {
                loggingService.warn(`üîÑ Agent retry attempt ${attempt}: ${error.message}`);
            }
        });
        
        void this.initializeLangchainIntegration();
        
        // Start cache cleanup interval
        this.startCacheCleanup();
    }

    /**
     * Initialize Langchain integration for enhanced multi-agent coordination
     */
    private async initializeLangchainIntegration(): Promise<void> {
        try {
            loggingService.info('üîó Initializing Langchain integration for AgentService');
            
            // Create specialized Langchain agents
            this.langchainAgents.set('tool_coordinator', new ChatBedrockConverse({
                model: 'anthropic.claude-3-5-haiku-20241022-v1:0',
                region: process.env.AWS_REGION || 'us-east-1',
                temperature: 0.5,
                maxTokens: 4000,
            }));
            
            this.langchainAgents.set('optimization_specialist', new ChatBedrockConverse({
                model: 'amazon.nova-pro-v1:0',
                region: process.env.AWS_REGION || 'us-east-1',
                temperature: 0.7,
                maxTokens: 6000,
            }));
            
            // Build Langchain state graph for tool coordination
            const AgentState = Annotation.Root({
                messages: Annotation<BaseMessage[]>({
                    reducer: (x, y) => x.concat(y),
                }),
                toolCalls: Annotation<string[]>({
                    reducer: (x, y) => [...(x || []), ...(y || [])],
                    default: () => [],
                }),
                toolResults: Annotation<Record<string, any>>({
                    reducer: (x, y) => y ?? x,
                    default: () => ({}),
                }),
                finalResponse: Annotation<string>({
                    reducer: (x, y) => y ?? x,
                }),
            });
            
            const workflow = new StateGraph(AgentState)
                .addNode('analyze', this.analyzeWithLangchain.bind(this))
                .addNode('execute_tools', this.executeToolsWithLangchain.bind(this))
                .addNode('synthesize', this.synthesizeWithLangchain.bind(this))
                .addEdge('__start__', 'analyze')
                .addEdge('analyze', 'execute_tools')
                .addEdge('execute_tools', 'synthesize')
                .addEdge('synthesize', '__end__');
            
            this.langchainGraph = workflow.compile() as any;
            this.isLangchainEnabled = true;
            
            loggingService.info('‚úÖ Langchain integration initialized successfully');
        } catch (error) {
            loggingService.warn('‚ö†Ô∏è Langchain integration failed to initialize', {
                error: error instanceof Error ? error.message : String(error)
            });
            this.isLangchainEnabled = false;
        }
    }

    /**
     * Analyze query with Langchain for better tool selection
     */
    private async analyzeWithLangchain(state: any): Promise<any> {
        const agent = this.langchainAgents.get('tool_coordinator');
        if (!agent) return state;
        
        const lastMessage = state.messages[state.messages.length - 1];
        const analysis = await agent.invoke([
            new SystemMessage('Analyze the query and determine which tools to use.'),
            lastMessage
        ]);
        
        // Extract tool recommendations (simplified)
        const toolCalls = this.extractToolRecommendations(analysis.content as string);
        
        return {
            ...state,
            toolCalls
        };
    }

    /**
     * Execute tools with Langchain coordination
     */
    private async executeToolsWithLangchain(state: any): Promise<any> {
        const toolResults: Record<string, any> = {};
        
        for (const toolName of state.toolCalls) {
            try {
                const tool = this.getToolInstance(toolName);
                const result = await tool.invoke({ input: state.messages[0].content });
                toolResults[toolName] = result;
            } catch (error) {
                loggingService.warn(`Tool execution failed: ${toolName}`, { error });
                toolResults[toolName] = { error: error instanceof Error ? error.message : String(error) };
            }
        }
        
        return {
            ...state,
            toolResults
        };
    }

    /**
     * Synthesize final response with Langchain
     */
    private async synthesizeWithLangchain(state: any): Promise<any> {
        const agent = this.langchainAgents.get('optimization_specialist');
        if (!agent) return state;
        
        const synthesisPrompt = new HumanMessage(`
            Query: ${state.messages[0].content}
            Tool Results: ${JSON.stringify(state.toolResults, null, 2)}
            
            Synthesize a comprehensive response using the tool results.
        `);
        
        const response = await agent.invoke([synthesisPrompt]);
        
        return {
            ...state,
            finalResponse: response.content as string
        };
    }

    /**
     * Extract tool recommendations from analysis
     */
    private extractToolRecommendations(analysis: string): string[] {
        const tools: string[] = [];
        const availableTools = Array.from(this.toolFactories.keys());
        
        // Simple extraction - check which tools are mentioned
        for (const toolName of availableTools) {
            if (analysis.toLowerCase().includes(toolName.replace('_', ' '))) {
                tools.push(toolName);
            }
        }
        
        // Default to knowledge base if no specific tools identified
        if (tools.length === 0) {
            tools.push('knowledge_base_search');
        }
        
        return tools;
    }

    /**
     * Initialize tool factories for lazy loading
     */
    private initializeToolFactories(): void {
        this.toolFactories.set('knowledge_base_search', () => new KnowledgeBaseTool());
        this.toolFactories.set('mongodb_reader', () => new MongoDbReaderTool());
        this.toolFactories.set('project_manager', () => new ProjectManagerTool());
        this.toolFactories.set('model_selector', () => new ModelSelectorTool());
        this.toolFactories.set('analytics_manager', () => new AnalyticsManagerTool());
        this.toolFactories.set('optimization_manager', () => new OptimizationManagerTool());
        this.toolFactories.set('web_search', () => new WebSearchTool());
        this.toolFactories.set('aws_integration', () => {
            const { AWSIntegrationTool } = require('../tools/awsIntegrationTool');
            return new AWSIntegrationTool();
        });
        
        loggingService.info('üîß Tool factories initialized for lazy loading');
    }
    
    /**
     * Get tool instance with lazy loading
     */
    private getToolInstance(toolName: string): Tool {
        if (!this.toolInstances.has(toolName)) {
            const factory = this.toolFactories.get(toolName);
            if (!factory) {
                throw new Error(`Unknown tool: ${toolName}`);
            }
            
            const tool = factory();
            this.toolInstances.set(toolName, tool);
            this.metrics.toolsLoaded++;
            
            loggingService.info(`üîß Lazy loaded tool: ${toolName}`);
        }
        
        return this.toolInstances.get(toolName)!;
    }
    
    /**
     * Get all required tools for agent initialization
     */
    private getAllTools(): Tool[] {
        if (this.tools.length === 0) {
            // Load all tools lazily
            this.tools = Array.from(this.toolFactories.keys()).map(toolName => 
                this.getToolInstance(toolName)
            );
        }
        return this.tools;
    }
    
    /**
     * Generate cache key for query
     */
    private generateCacheKey(queryData: AgentQuery): string {
        const queryHash = crypto.createHash('md5')
            .update(JSON.stringify({
                query: queryData.query,
                userId: queryData.userId,
                context: queryData.context
            }))
            .digest('hex');
        return queryHash;
    }
    
    /**
     * Get cached response if available
     */
    private getCachedResponse(cacheKey: string): AgentResponse | null {
        const cached = this.responseCache.get(cacheKey);
        if (cached && Date.now() - cached.timestamp < this.RESPONSE_CACHE_TTL) {
            cached.hits++;
            this.metrics.cacheHits++;
            loggingService.info('üíæ Cache hit for query', { cacheKey, hits: cached.hits });
            const cachedResponse = { ...cached.response };
            if (cachedResponse.metadata) {
                cachedResponse.metadata.fromCache = true;
            } else {
                cachedResponse.metadata = { fromCache: true };
            }
            return cachedResponse;
        }
        
        if (cached) {
            this.responseCache.delete(cacheKey);
        }
        
        this.metrics.cacheMisses++;
        return null;
    }
    
    /**
     * Cache response
     */
    private cacheResponse(cacheKey: string, response: AgentResponse): void {
        // Implement LRU eviction if cache is full
        if (this.responseCache.size >= this.MAX_CACHE_SIZE) {
            const oldestKey = this.responseCache.keys().next().value;
            if (oldestKey) {
                this.responseCache.delete(oldestKey);
            }
        }
        
        this.responseCache.set(cacheKey, {
            response: { ...response },
            timestamp: Date.now(),
            hits: 0
        });
        
        loggingService.info('üíæ Response cached', { cacheKey, cacheSize: this.responseCache.size });
    }
    
    /**
     * Start cache cleanup interval
     */
    private startCacheCleanup(): void {
        const cleanupInterval = setInterval(() => {
            const now = Date.now();
            let cleaned = 0;
            
            // Clean response cache
            for (const [key, cached] of this.responseCache.entries()) {
                if (now - cached.timestamp > this.RESPONSE_CACHE_TTL) {
                    this.responseCache.delete(key);
                    cleaned++;
                }
            }
            
            // Clean user context cache
            for (const [key, cached] of this.userContextCache.entries()) {
                if (now - cached.timestamp > this.USER_CONTEXT_CACHE_TTL) {
                    this.userContextCache.delete(key);
                    cleaned++;
                }
            }
            
            if (cleaned > 0) {
                loggingService.info(`üßπ Cache cleanup: removed ${cleaned} expired entries`);
            }
        }, 60000); // Run every minute
        
        // Store interval reference for potential cleanup
        (this as any).cleanupInterval = cleanupInterval;
    }
    
    /**
     * Create timeout promise with proper cleanup
     */
    private createTimeoutPromise<T>(ms: number): Promise<never> {
        return new Promise((_, reject) => {
            const timeoutId = setTimeout(() => {
                clearTimeout(timeoutId);
                reject(new Error(`Agent execution timeout after ${ms / 1000} seconds`));
            }, ms);
        });
    }
    
    /**
     * Initialize the agent with all necessary components
     */
    async initialize(): Promise<void> {
        if (this.initialized) return;

        try {
            loggingService.info('ü§ñ Initializing AIOps Agent...');

            // Initialize vector store first with timeout to prevent hanging
            try {
                await Promise.race([
                    vectorStoreService.initialize(),
                    new Promise((_, reject) => 
                        setTimeout(() => reject(new Error('Vector store initialization timeout')), 30000)
                    )
                ]);
            } catch (vectorError) {
                loggingService.warn('‚ö†Ô∏è Vector store initialization failed or timed out, continuing without it:', {
                    error: vectorError instanceof Error ? vectorError.message : String(vectorError)
                });
                // Continue initialization even if vector store fails
            }

            // Build user context
            const userContext = this.buildUserContext({ userId: 'system', query: '', context: {} });
            
            // Create optimized prompt template
            const systemPrompt = process.env.NODE_ENV === 'production' 
                ? getCompressedPrompt() 
                : buildSystemPrompt(userContext);
            
            const prompt = ChatPromptTemplate.fromMessages([
                SystemMessagePromptTemplate.fromTemplate(systemPrompt),
                HumanMessagePromptTemplate.fromTemplate("{input}")
            ]);

            // Get all tools (lazy loaded)
            const allTools = this.getAllTools();
            
            // Create React agent with tools
            const agent = await createReactAgent({
                llm: this.model,
                tools: allTools,
                prompt: prompt,
            });

            // Create agent executor
            this.agentExecutor = new AgentExecutor({
                agent,
                tools: allTools,
                verbose: process.env.NODE_ENV === 'development',
                maxIterations: 3, // Even more aggressive to prevent loops
                earlyStoppingMethod: "force",
                returnIntermediateSteps: true, // Need this to extract tool outputs
                handleParsingErrors: true, // Better error handling
            });

            this.initialized = true;
            loggingService.info('‚úÖ AIOps Agent initialized successfully');
            
        } catch (error) {
            loggingService.error('‚ùå Failed to initialize agent:', { error: error instanceof Error ? error.message : String(error) });
            throw new Error('Agent initialization failed');
        }
    }

    /**
     * Process a query from a user
     */
    async query(queryData: AgentQuery): Promise<AgentResponse> {
        const startTime = Date.now();
        this.metrics.totalRequests++;

        try {
            // Check cache first
            const cacheKey = this.generateCacheKey(queryData);
            const cachedResponse = this.getCachedResponse(cacheKey);
            if (cachedResponse) {
                return cachedResponse;
            }

            if (!this.initialized) {
                await this.initialize();
            }

            // Use Langchain integration if enabled and query is complex
            if (this.isLangchainEnabled && this.shouldUseLangchainIntegration(queryData)) {
                loggingService.info('üîó Using Langchain integration for enhanced processing');
                return await this.queryWithLangchain(queryData);
            }

            if (!this.agentExecutor) {
                throw new Error('Agent not properly initialized');
            }

            // Dynamically add Vercel tools if user has a Vercel connection
            await this.addVercelToolsIfConnected(queryData.userId);

            // Log query for debugging
            loggingService.info('üîç Processing user query', { 
                query: queryData.query.substring(0, 100),
                userId: queryData.userId
            });

            // Build user context (with caching)
            const userContext = this.buildUserContextCached(queryData);

            // Check if query contains context preamble (from chat service)
            let enhancedQuery = queryData.query;
            if (queryData.query.includes('Current subject:') || queryData.query.includes('Recent conversation:')) {
                // This is a context-enhanced query from chat service
                loggingService.info('üîç Context-enhanced query detected', {
                    hasContextPreamble: true,
                    queryLength: queryData.query.length
                });
                enhancedQuery = queryData.query; // Use as-is since it already contains context
            }

            // Generate thinking process for cost-related queries
            const thinking = this.generateThinkingProcess(enhancedQuery);

            // Determine query type for prompt optimization
            const queryType = this.determineQueryType(enhancedQuery);

            // Use queryType in the agentExecutor input for prompt optimization
            const result = await Promise.race([
                this.circuitBreaker(async () => {
                    return await this.retryExecutor(async () => {
                        return await this.agentExecutor!.invoke({
                            input: enhancedQuery,
                            user_context: userContext,
                            queryType // Pass queryType to the agent
                        }, {
                            callbacks: queryData.callbacks // Pass callbacks if provided
                        });
                    });
                }),
                this.createTimeoutPromise(60000)
            ]) as any;

            const executionTime = Date.now() - startTime;

            // Update performance metrics
            this.updatePerformanceMetrics(executionTime);

            // Handle retry wrapper result structure
            let actualResult = result;
            if (result.success && result.result) {
                // This is wrapped by retry mechanism, extract the actual result
                actualResult = result.result;
                loggingService.info('üîÑ Detected retry wrapper, extracting actual result');
            }

            // Process the result to ensure we always have a proper response
            let finalResponse = actualResult.output;

            // Debug logging to understand what we got from the agent
            loggingService.info('üîç Agent Result Debug:', {
                isWrapped: result.success && result.result,
                hasOutput: !!actualResult.output,
                outputLength: actualResult.output?.length || 0,
                outputPreview: actualResult.output?.substring(0, 200) + '...',
                hasIntermediateSteps: !!actualResult.intermediateSteps,
                stepsCount: actualResult.intermediateSteps?.length || 0,
                resultKeys: Object.keys(result),
                actualResultKeys: Object.keys(actualResult)
            });

            // If the agent hit max iterations without a proper Final Answer, extract useful info
            if (!finalResponse || finalResponse.includes('Agent stopped due to max iterations')) {
                loggingService.info('‚ö†Ô∏è Agent output is falsy or contains max iterations, extracting from intermediate steps...');
                finalResponse = this.extractUsefulResponse(actualResult, queryData.query);
                loggingService.info('üìã Extracted response:', {
                    length: finalResponse?.length || 0,
                    preview: finalResponse?.substring(0, 200) + '...'
                });
            } else {
                loggingService.info('‚úÖ Agent provided proper output directly');
            }

            const response: AgentResponse = {
                success: true,
                response: finalResponse,
                metadata: {
                    executionTime,
                    sources: this.extractSources(actualResult),
                    fromCache: false
                },
                thinking: thinking
            };

            // Cache successful responses
            if (response.success && response.response) {
                this.cacheResponse(cacheKey, response);
            }

            return response;

        } catch (error) {
            loggingService.error('Agent query failed:', { error: error instanceof Error ? error.message : String(error) });

            // Handle specific error types
            let errorMessage = error instanceof Error ? error.message : 'Unknown error occurred';
            let fallbackResponse = '';

            // Check if it's a max iterations or timeout error
            if (errorMessage.includes('max iterations') || errorMessage.includes('Agent stopped due to max iterations')) {
                errorMessage = 'The query was complex and took longer than expected to process.';
                fallbackResponse = 'I was working on analyzing your data but the query became too complex. Could you please rephrase your question to be more specific? For example:\n\n' +
                    '‚Ä¢ "Show my spending for this month"\n' +
                    '‚Ä¢ "What are my top 3 most expensive models?"\n' +
                    '‚Ä¢ "How many tokens did I use last week?"';
            } else if (errorMessage.includes('timeout')) {
                errorMessage = 'The query took too long to process and timed out.';
                fallbackResponse = 'Your request timed out after 60 seconds. Please try a simpler, more specific question. For example:\n\n' +
                    '‚Ä¢ "What did I spend this month?"\n' +
                    '‚Ä¢ "Show my top 5 models by cost"\n' +
                    '‚Ä¢ "How many requests did I make today?"';
            }

            return {
                success: false,
                error: errorMessage,
                response: fallbackResponse,
                metadata: {
                    executionTime: Date.now() - startTime,
                    errorType: errorMessage.includes('max iterations') ? 'max_iterations' : 'general_error'
                }
            };
        }
    }

    /**
     * Determine if Langchain integration should be used
     */
    private shouldUseLangchainIntegration(queryData: AgentQuery): boolean {
        const query = queryData.query.toLowerCase();
        
        // Use Langchain for complex multi-tool scenarios
        const complexIndicators = [
            'analyze and optimize',
            'comprehensive report',
            'multiple services',
            'cross-platform',
            'integrate with',
            'coordinate between'
        ];
        
        return complexIndicators.some(indicator => query.includes(indicator)) ||
               queryData.context?.useMultiAgent === true;
    }

    /**
     * Process query using Langchain integration
     */
    private async queryWithLangchain(queryData: AgentQuery): Promise<AgentResponse> {
        const startTime = Date.now();
        
        try {
            if (!this.langchainGraph) {
                throw new Error('Langchain graph not initialized');
            }
            
            const initialState = {
                messages: [new HumanMessage(queryData.query)],
                toolCalls: [],
                toolResults: {},
                finalResponse: ''
            };
            
            const result = await (this.langchainGraph as any).invoke(initialState);
            
            const executionTime = Date.now() - startTime;
            
            return {
                success: true,
                response: result.finalResponse || 'Query processed successfully',
                metadata: {
                    executionTime,
                    sources: Object.keys(result.toolResults),
                    fromCache: false,
                    langchainEnhanced: true
                },
                thinking: {
                    title: 'Langchain-Enhanced Processing',
                    steps: result.toolCalls.map((tool: string, idx: number) => ({
                        step: idx + 1,
                        description: `Execute ${tool}`,
                        reasoning: 'Selected by Langchain analysis',
                        outcome: result.toolResults[tool] ? 'Success' : 'Failed'
                    }))
                }
            };
        } catch (error) {
            loggingService.error('Langchain query processing failed', {
                error: error instanceof Error ? error.message : String(error)
            });
            
            // Fallback to standard processing
            return this.query({ ...queryData, context: { ...queryData.context, useMultiAgent: false } });
        }
    }

    /**
     * Extract useful response from agent result even if it hit max iterations
     * Optimized version using response formatters
     */
    private extractUsefulResponse(result: any, originalQuery: string): string {
        try {
            // Look for tool outputs in the agent's intermediate steps or logs
            const intermediateSteps = result.intermediateSteps || [];
            const logs = result.log || '';
            
            // Try to find the last tool output
            let lastToolOutput = null;
            
            // Check intermediate steps for tool outputs
            for (const step of intermediateSteps) {
                if (step.observation) {
                    try {
                        // Try to parse the observation as JSON
                        lastToolOutput = typeof step.observation === 'string' 
                            ? JSON.parse(step.observation) 
                            : step.observation;
                        loggingService.info('üîß Found tool output in intermediate steps:', { 
                            success: lastToolOutput?.success,
                            operation: lastToolOutput?.operation,
                            hasData: !!lastToolOutput?.data
                        });
                    } catch (e) {
                        // If it's not JSON, keep as string
                        lastToolOutput = step.observation;
                        loggingService.info('üîß Found non-JSON tool output:', { output: step.observation?.substring(0, 100) + '...' });
                    }
                }
            }
            
            // If no intermediate steps, try to parse from logs
            if (!lastToolOutput && logs) {
                const toolOutputMatch = logs.match(/Observation: ({.*?})/s);
                if (toolOutputMatch) {
                    try {
                        lastToolOutput = JSON.parse(toolOutputMatch[1]);
                    } catch (e) {
                        lastToolOutput = toolOutputMatch[1];
                    }
                }
            }
            
            // If we found tool output, format it using the response formatters
            if (lastToolOutput) {
                if (typeof lastToolOutput === 'string') {
                    try {
                        lastToolOutput = JSON.parse(lastToolOutput);
                    } catch (e) {
                        // Keep as string
                    }
                }
                
                // Use response formatters for consistent formatting
                if (lastToolOutput && typeof lastToolOutput === 'object' && lastToolOutput.success) {
                    loggingService.info('üéØ Processing tool output with formatters:', {
                        success: lastToolOutput.success,
                        operation: lastToolOutput.operation,
                        hasData: !!lastToolOutput.data
                    });
                    
                    return ResponseFormattersService.formatResponse(lastToolOutput);
                }
                
                // Handle non-successful tool output
                if (lastToolOutput && lastToolOutput.success === false) {
                    return lastToolOutput.message || 'The operation was not successful.';
                }
            }
            
            // Use fallback response generator
            loggingService.info('üö® No successful tool output found, using fallback response');
            return ResponseFormattersService.generateFallbackResponse(originalQuery);
            
        } catch (error) {
            loggingService.error('Error extracting useful response:', { error: error instanceof Error ? error.message : String(error) });
            return "I encountered an issue processing your request. Please try asking a more specific question, such as 'What did I spend this month?' or 'Show my token usage.'";
        }
    }

    /**
     * Get agent status and statistics
     */
    getStatus(): {
        initialized: boolean;
        model: string;
        agentType: string;
        toolsCount: number;
        toolsLoaded: number;
        vectorStoreStats: any;
        performance: any;
        cacheStats: {
            responseCache: number;
            userContextCache: number;
        };
    } {
        const isMasterAgent = process.env.AGENT_TYPE === 'master';
        const currentModel = isMasterAgent ? 'anthropic.claude-sonnet-4-20250514-v1:0' : (process.env.AWS_BEDROCK_MODEL_ID || 'amazon.nova-pro-v1:0');
        
        return {
            initialized: this.initialized,
            model: currentModel,
            agentType: isMasterAgent ? 'Master Agent (Complex Reasoning)' : 'Standard Agent (Nova Pro)',
            toolsCount: this.toolFactories.size,
            toolsLoaded: this.toolInstances.size,
            vectorStoreStats: vectorStoreService.getStats(),
            performance: this.getMetrics(),
            cacheStats: {
                responseCache: this.responseCache.size,
                userContextCache: this.userContextCache.size
            }
        };
    }

    /**
     * Add learned insight to the knowledge base
     */
    async addLearning(insight: string, metadata: Record<string, any> = {}): Promise<void> {
        try {
            await vectorStoreService.addKnowledge(insight, {
                ...metadata,
                learningSource: 'agent_interaction'
            });
        } catch (error) {
            loggingService.error('Failed to add learning:', { error: error instanceof Error ? error.message : String(error) });
        }
    }

    /**
     * Build user context for the agent (with caching)
     */
    private buildUserContextCached(queryData: AgentQuery): string {
        const contextKey = `${queryData.userId}_${queryData.context?.projectId || 'default'}_${queryData.context?.conversationId || 'default'}`;
        
        const cached = this.userContextCache.get(contextKey);
        if (cached && Date.now() - cached.timestamp < this.USER_CONTEXT_CACHE_TTL) {
            return cached.context;
        }
        
        const context = this.buildUserContext(queryData);
        
        this.userContextCache.set(contextKey, {
            context,
            timestamp: Date.now()
        });
        
        return context;
    }
    
    /**
     * Build user context for the agent
     */
    private buildUserContext(queryData: AgentQuery): string {
        let context = `User ID: ${queryData.userId}`;
        
        if (queryData.context?.projectId) {
            context += `\nProject ID: ${queryData.context.projectId}`;
        }
        
        if (queryData.context?.conversationId) {
            context += `\nConversation ID: ${queryData.context.conversationId}`;
        }

        if (queryData.context?.previousMessages && queryData.context.previousMessages.length > 0) {
            context += '\nRecent conversation:\n';
            queryData.context.previousMessages.slice(-3).forEach((msg: any) => {
                let messageContent = msg.content;
                
                // Only include document content metadata if the query is document-related
                // This prevents old document context from polluting new queries about integrations (Vercel, GitHub, etc.)
                const isDocumentQuery = queryData.query.toLowerCase().includes('document') || 
                                       queryData.query.toLowerCase().includes('file') ||
                                       queryData.query.toLowerCase().includes('pdf') ||
                                       queryData.query.toLowerCase().includes('what does it say') ||
                                       queryData.query.toLowerCase().includes('what did') ||
                                       queryData.query.toLowerCase().includes('analyze');
                
                if (msg.metadata?.type === 'document_content' && msg.metadata?.content && isDocumentQuery) {
                    const maxContentLength = 8000; // Limit for agent context
                    const docContent = msg.metadata.content.length > maxContentLength 
                        ? msg.metadata.content.substring(0, maxContentLength) + '... [truncated]'
                        : msg.metadata.content;
                    messageContent = `${msg.content}\n[Document Content]: ${docContent}`;
                }
                
                context += `${msg.role}: ${messageContent}\n`;
            });
        }

        return context;
    }
    
    /**
     * Update performance metrics
     */
    private updatePerformanceMetrics(executionTime: number): void {
        // Update average response time using exponential moving average
        const alpha = 0.1; // Smoothing factor
        this.metrics.avgResponseTime = this.metrics.avgResponseTime === 0 
            ? executionTime 
            : (alpha * executionTime) + ((1 - alpha) * this.metrics.avgResponseTime);
    }
    
    /**
     * Get performance metrics
     */
    getMetrics(): typeof this.metrics & { cacheHitRate: number; toolsLoadedCount: number } {
        const totalCacheRequests = this.metrics.cacheHits + this.metrics.cacheMisses;
        const cacheHitRate = totalCacheRequests > 0 ? (this.metrics.cacheHits / totalCacheRequests) * 100 : 0;
        
        return {
            ...this.metrics,
            cacheHitRate: Math.round(cacheHitRate * 100) / 100,
            toolsLoadedCount: this.toolInstances.size
        };
    }
    
    /**
     * Clear caches (for testing or maintenance)
     */
    clearCaches(): void {
        this.responseCache.clear();
        this.userContextCache.clear();
        loggingService.info('üßπ All caches cleared');
    }
    
    /**
     * Determine query type for prompt optimization
     */
    private determineQueryType(query: string): 'cost' | 'token' | 'performance' | 'general' {
        const lowerQuery = query.toLowerCase();
        
        if (lowerQuery.includes('token') || lowerQuery.includes('usage')) {
            return 'token';
        } else if (lowerQuery.includes('cost') || lowerQuery.includes('spend') || lowerQuery.includes('budget')) {
            return 'cost';
        } else if (lowerQuery.includes('performance') || lowerQuery.includes('model') || lowerQuery.includes('benchmark')) {
            return 'performance';
        } else {
            return 'general';
        }
    }

    /**
     * Generate thinking process for ALL query types - comprehensive coverage
     */
    private generateThinkingProcess(query: string): any {
        const lowerQuery = query.toLowerCase();
        
        // Enhanced thinking for empty/no data scenarios
        if (lowerQuery.includes('no') && lowerQuery.includes('data') || 
            lowerQuery.includes('empty') || lowerQuery.includes('n/a')) {
            return {
                title: "Data Investigation & User Support",
                summary: "I'll help you understand why no data was found and guide you through the next steps to get meaningful insights.",
                steps: [
                    {
                        step: 1,
                        description: "Expanding search parameters",
                        reasoning: "Time range might be too narrow - checking broader periods",
                        outcome: "Searching last 90 days instead of current month"
                    },
                    {
                        step: 2,
                        description: "Checking data availability",
                        reasoning: "Need to understand if user is new or has different usage patterns",
                        outcome: "Will provide setup guidance if needed"
                    },
                    {
                        step: 3,
                        description: "Preparing interactive guidance",
                        reasoning: "User needs actionable next steps, not generic responses",
                        outcome: "Will ask specific questions to better assist"
                    }
                ]
            };
        }
        
        // 1. COST & SPENDING QUERIES
        const isCostQuery = lowerQuery.includes('cost') || lowerQuery.includes('money') || 
                           lowerQuery.includes('spend') || lowerQuery.includes('expensive') ||
                           lowerQuery.includes('price') || lowerQuery.includes('budget') ||
                           lowerQuery.includes('model') || lowerQuery.includes('usage');
        
        if (isCostQuery) {
            return {
                title: "Analyzing your AI cost data",
                summary: "I need to query your actual usage data to provide accurate cost insights based on your real spending patterns.",
                steps: [
                    {
                        step: 1,
                        description: "Data Retrieval",
                        reasoning: "First, I'll query your usage database to get your actual AI model spending data, including costs by model, service, and time period.",
                        outcome: "Retrieved your real usage data from MongoDB"
                    },
                    {
                        step: 2,
                        description: "Cost Analysis",
                        reasoning: "I'll analyze your spending patterns to identify which models consume the most budget and calculate total expenditures.",
                        outcome: "Identified your highest-cost models and spending trends"
                    },
                    {
                        step: 3,
                        description: "Data Aggregation",
                        reasoning: "I'll aggregate the costs by different dimensions (model, provider, time) to give you comprehensive insights.",
                        outcome: "Summarized your costs with actionable breakdowns"
                    },
                    {
                        step: 4,
                        description: "Optimization Recommendations",
                        reasoning: "Based on your actual spending patterns, I'll suggest specific optimizations to reduce costs.",
                        outcome: "Generated personalized cost optimization strategies"
                    }
                ]
            };
        }
        
        // 2. API CONFIGURATION QUERIES
        const isApiConfigQuery = lowerQuery.includes('api') || lowerQuery.includes('configure') ||
                                 lowerQuery.includes('settings') || lowerQuery.includes('key') ||
                                 lowerQuery.includes('integration') || lowerQuery.includes('endpoint');
        
        if (isApiConfigQuery) {
            return {
                title: "Configuring your API settings",
                summary: "I'll analyze your current integrations and guide you through optimizing your API configurations for better cost efficiency.",
                steps: [
                    {
                        step: 1,
                        description: "Current Configuration Analysis",
                        reasoning: "First, I'll check your existing API keys, endpoints, and integration settings to understand your current setup.",
                        outcome: "Identified your active integrations and configuration gaps"
                    },
                    {
                        step: 2,
                        description: "Security & Best Practices Review",
                        reasoning: "I'll verify your API security settings and recommend best practices for key management and access control.",
                        outcome: "Enhanced security configuration recommendations"
                    },
                    {
                        step: 3,
                        description: "Cost Optimization Setup",
                        reasoning: "I'll configure optimal settings for rate limiting, caching, and request optimization to minimize API costs.",
                        outcome: "Implemented cost-effective API configurations"
                    },
                    {
                        step: 4,
                        description: "Testing & Validation",
                        reasoning: "I'll test your API connections and validate that all configurations are working optimally.",
                        outcome: "Verified all API integrations are functioning efficiently"
                    }
                ]
            };
        }

        // 3. TOKEN USAGE & ANALYTICS QUERIES
        const isTokenUsageQuery = lowerQuery.includes('token') || lowerQuery.includes('usage') ||
                                  lowerQuery.includes('analytics') || lowerQuery.includes('current') ||
                                  lowerQuery.includes('how much') || lowerQuery.includes('statistics');
        
        if (isTokenUsageQuery) {
            return {
                title: "Analyzing your current token usage",
                summary: "I'll dive deep into your actual usage data to provide comprehensive insights about your token consumption patterns.",
                steps: [
                    {
                        step: 1,
                        description: "Real-Time Data Retrieval",
                        reasoning: "I'll query your usage database to get your most recent token consumption across all models and projects.",
                        outcome: "Retrieved your current token usage statistics"
                    },
                    {
                        step: 2,
                        description: "Usage Pattern Analysis",
                        reasoning: "I'll analyze your usage patterns to identify peak times, model preferences, and consumption trends.",
                        outcome: "Identified your usage patterns and optimization opportunities"
                    },
                    {
                        step: 3,
                        description: "Cost Impact Assessment",
                        reasoning: "I'll calculate the cost implications of your token usage and compare against your budgets and thresholds.",
                        outcome: "Generated cost breakdown and budget utilization analysis"
                    },
                    {
                        step: 4,
                        description: "Optimization Recommendations",
                        reasoning: "Based on your actual usage data, I'll provide specific recommendations to optimize token consumption.",
                        outcome: "Created personalized token optimization strategy"
                    }
                ]
            };
        }

        // 4. PROMPT OPTIMIZATION QUERIES
        const isPromptOptQuery = lowerQuery.includes('prompt') || lowerQuery.includes('optimize') ||
                                lowerQuery.includes('efficiency') || lowerQuery.includes('improve') ||
                                lowerQuery.includes('better') || lowerQuery.includes('reduce');
        
        if (isPromptOptQuery) {
            return {
                title: "Optimizing your prompts for efficiency",
                summary: "I'll analyze your actual prompts and usage patterns to provide specific optimization strategies that reduce costs while maintaining quality.",
                steps: [
                    {
                        step: 1,
                        description: "Prompt Analysis",
                        reasoning: "I'll examine your recent prompts to identify optimization opportunities like redundancy, verbosity, and inefficient structures.",
                        outcome: "Identified optimization opportunities in your prompts"
                    },
                    {
                        step: 2,
                        description: "Token Efficiency Review",
                        reasoning: "I'll calculate current token usage and identify where prompt compression can reduce costs without losing effectiveness.",
                        outcome: "Found token reduction opportunities averaging 25-40%"
                    },
                    {
                        step: 3,
                        description: "Template Creation",
                        reasoning: "I'll create optimized prompt templates based on your use cases that maintain quality while reducing token count.",
                        outcome: "Generated efficient prompt templates for your common use cases"
                    },
                    {
                        step: 4,
                        description: "Quality Validation",
                        reasoning: "I'll test optimized prompts to ensure they maintain output quality while achieving cost savings.",
                        outcome: "Validated optimizations maintain 95%+ quality with significant cost reduction"
                    }
                ]
            };
        }

        // 5. MODEL SELECTION & COMPARISON QUERIES
        const isModelQuery = lowerQuery.includes('model') || lowerQuery.includes('compare') ||
                            lowerQuery.includes('recommend') || lowerQuery.includes('best') ||
                            lowerQuery.includes('switch') || lowerQuery.includes('alternative');
        
        if (isModelQuery) {
            return {
                title: "Analyzing optimal model selection",
                summary: "I'll analyze your usage patterns and requirements to recommend the most cost-effective models for your specific needs.",
                steps: [
                    {
                        step: 1,
                        description: "Usage Pattern Analysis",
                        reasoning: "I'll examine your current model usage, task complexity, and quality requirements to understand your needs.",
                        outcome: "Mapped your usage patterns to optimal model categories"
                    },
                    {
                        step: 2,
                        description: "Cost-Performance Comparison",
                        reasoning: "I'll compare costs and performance across available models to identify the best value options for each use case.",
                        outcome: "Identified 3-5 optimal models with cost/quality trade-offs"
                    },
                    {
                        step: 3,
                        description: "ROI Calculation",
                        reasoning: "I'll calculate potential cost savings and performance impacts from switching to recommended models.",
                        outcome: "Estimated 15-35% cost savings with maintained quality"
                    },
                    {
                        step: 4,
                        description: "Migration Strategy",
                        reasoning: "I'll create a safe migration plan to gradually transition to optimal models with testing and validation.",
                        outcome: "Generated risk-free model migration roadmap"
                    }
                ]
            };
        }

        // 6. PROJECT SETUP & MANAGEMENT QUERIES
        if (lowerQuery.includes('project') || lowerQuery.includes('setup')) {
            // Special handling for AI cost optimization projects
            if (lowerQuery.includes('cost') || lowerQuery.includes('optim')) {
                return {
                    title: "Setting up AI Cost Optimization Project",
                    summary: "I'll create a comprehensive AI cost optimization project with monitoring, analytics, and optimization tools configured for maximum cost efficiency.",
                    steps: [
                        {
                            step: 1,
                            description: "Project Configuration",
                            reasoning: "Setting up an AI cost optimization project with specialized settings, higher budget limits, and sensitive cost alerts.",
                            outcome: "Created optimized project with $500 budget and 60% alert threshold"
                        },
                        {
                            step: 2,
                            description: "Model Portfolio Setup",
                            reasoning: "Configuring a diverse set of models from Nova Lite (cost-effective) to Claude Sonnet (high-quality) for comprehensive testing.",
                            outcome: "Added 4 optimized models for cost/performance comparisons"
                        },
                        {
                            step: 3,
                            description: "Monitoring Infrastructure",
                            reasoning: "Setting up comprehensive usage tracking, cost analytics, and automated alerting systems.",
                            outcome: "Configured advanced monitoring and reporting capabilities"
                        },
                        {
                            step: 4,
                            description: "Optimization Strategy",
                            reasoning: "Implementing cost optimization techniques including prompt engineering, caching, and automated model selection.",
                            outcome: "Deployed 7 optimization strategies for immediate cost savings"
                        },
                        {
                            step: 5,
                            description: "Implementation Roadmap",
                            reasoning: "Providing step-by-step guidance for implementing cost optimization best practices.",
                            outcome: "Generated 8-step action plan for immediate implementation"
                        }
                    ]
                };
            }
            
            // General project setup
            return {
                title: "Planning your project setup",
                summary: "I'll break down your project requirements and create a structured implementation plan.",
                steps: [
                    {
                        step: 1,
                        description: "Requirement Analysis",
                        reasoning: "Understanding your specific needs, technology preferences, and project goals.",
                        outcome: "Clarified project scope and requirements"
                    },
                    {
                        step: 2,
                        description: "Technology Stack Selection",
                        reasoning: "Choosing the optimal technologies based on your requirements and cost optimization goals.",
                        outcome: "Selected appropriate tools and frameworks"
                    },
                    {
                        step: 3,
                        description: "Implementation Planning",
                        reasoning: "Creating a step-by-step implementation plan that's easy to follow and execute.",
                        outcome: "Structured implementation roadmap"
                    }
                ]
            };
        }

        // 7. ANALYTICS & INSIGHTS QUERIES
        const isAnalyticsQuery = lowerQuery.includes('insight') || lowerQuery.includes('report') ||
                                 lowerQuery.includes('trend') || lowerQuery.includes('pattern') ||
                                 lowerQuery.includes('dashboard') || lowerQuery.includes('metrics');
        
        if (isAnalyticsQuery) {
            return {
                title: "Generating analytics and insights",
                summary: "I'll analyze your comprehensive usage data to provide actionable insights and trends for optimizing your AI spending.",
                steps: [
                    {
                        step: 1,
                        description: "Data Aggregation",
                        reasoning: "I'll gather all your usage data across models, projects, and time periods to build a complete picture of your AI usage.",
                        outcome: "Compiled comprehensive usage dataset for analysis"
                    },
                    {
                        step: 2,
                        description: "Trend Analysis",
                        reasoning: "I'll identify spending trends, usage patterns, and seasonal variations in your AI consumption.",
                        outcome: "Discovered key trends and usage patterns"
                    },
                    {
                        step: 3,
                        description: "Anomaly Detection",
                        reasoning: "I'll identify unusual spending spikes, efficiency drops, or other anomalies that need attention.",
                        outcome: "Flagged anomalies and potential optimization opportunities"
                    },
                    {
                        step: 4,
                        description: "Actionable Recommendations",
                        reasoning: "Based on the analysis, I'll provide specific, prioritized recommendations for cost optimization.",
                        outcome: "Generated prioritized action plan with ROI estimates"
                    }
                ]
            };
        }

        // 8. PERFORMANCE & OPTIMIZATION QUERIES
        const isPerformanceQuery = lowerQuery.includes('performance') || lowerQuery.includes('speed') ||
                                  lowerQuery.includes('latency') || lowerQuery.includes('quality') ||
                                  lowerQuery.includes('accuracy') || lowerQuery.includes('benchmark');
        
        if (isPerformanceQuery) {
            return {
                title: "Analyzing performance optimization opportunities",
                summary: "I'll evaluate your AI system performance across cost, speed, and quality metrics to identify optimization opportunities.",
                steps: [
                    {
                        step: 1,
                        description: "Performance Baseline Assessment",
                        reasoning: "I'll establish current performance baselines across all your AI operations including latency, cost, and quality metrics.",
                        outcome: "Established comprehensive performance baselines"
                    },
                    {
                        step: 2,
                        description: "Bottleneck Identification",
                        reasoning: "I'll identify performance bottlenecks in your AI pipeline that impact cost efficiency or response times.",
                        outcome: "Identified key bottlenecks and performance constraints"
                    },
                    {
                        step: 3,
                        description: "Optimization Strategy Development",
                        reasoning: "I'll develop targeted optimization strategies that improve performance while maintaining or reducing costs.",
                        outcome: "Created multi-faceted performance optimization plan"
                    },
                    {
                        step: 4,
                        description: "Implementation Roadmap",
                        reasoning: "I'll prioritize optimizations by impact and create a practical implementation timeline with measurable goals.",
                        outcome: "Generated implementation roadmap with success metrics"
                    }
                ]
            };
        }

        // 9. SECURITY & COMPLIANCE QUERIES
        const isSecurityQuery = lowerQuery.includes('security') || lowerQuery.includes('compliance') ||
                               lowerQuery.includes('privacy') || lowerQuery.includes('audit') ||
                               lowerQuery.includes('permission') || lowerQuery.includes('access');
        
        if (isSecurityQuery) {
            return {
                title: "Reviewing security and compliance configuration",
                summary: "I'll audit your AI system's security posture and compliance settings to ensure robust protection while maintaining efficiency.",
                steps: [
                    {
                        step: 1,
                        description: "Security Configuration Audit",
                        reasoning: "I'll review all API keys, access controls, and security configurations to identify potential vulnerabilities.",
                        outcome: "Completed comprehensive security audit"
                    },
                    {
                        step: 2,
                        description: "Compliance Assessment",
                        reasoning: "I'll verify compliance with relevant regulations and best practices for AI system deployment.",
                        outcome: "Assessed compliance status and identified gaps"
                    },
                    {
                        step: 3,
                        description: "Risk Mitigation Planning",
                        reasoning: "I'll develop strategies to address security risks while maintaining operational efficiency and cost effectiveness.",
                        outcome: "Created risk mitigation plan with cost considerations"
                    },
                    {
                        step: 4,
                        description: "Implementation Guidelines",
                        reasoning: "I'll provide specific implementation steps to enhance security without compromising AI system performance.",
                        outcome: "Generated secure implementation guidelines"
                    }
                ]
            };
        }

        // 10. GENERAL AI ASSISTANCE QUERIES
        const isGeneralQuery = lowerQuery.includes('help') || lowerQuery.includes('guide') ||
                              lowerQuery.includes('how to') || lowerQuery.includes('explain') ||
                              lowerQuery.includes('what is') || lowerQuery.includes('show me');
        
        if (isGeneralQuery) {
            return {
                title: "Analyzing your request for intelligent assistance",
                summary: "I'll understand your specific needs and provide comprehensive, data-driven guidance tailored to your AI cost optimization goals.",
                steps: [
                    {
                        step: 1,
                        description: "Context Understanding",
                        reasoning: "I'll analyze your request in the context of your existing AI usage, projects, and optimization goals.",
                        outcome: "Understood your specific context and requirements"
                    },
                    {
                        step: 2,
                        description: "Resource Identification",
                        reasoning: "I'll identify relevant data, tools, and resources from your system to provide the most helpful response.",
                        outcome: "Compiled relevant resources and data points"
                    },
                    {
                        step: 3,
                        description: "Solution Development",
                        reasoning: "I'll develop a comprehensive solution or guidance that addresses your specific situation and goals.",
                        outcome: "Crafted personalized solution with actionable steps"
                    }
                ]
            };
        }
        
        // Return undefined for very basic queries that don't need thinking process
        return undefined;
    }

    /**
     * Extract sources from agent execution result
     */
    private extractSources(result: any): string[] {
        const sources: string[] = [];
        
        // This would be enhanced based on actual agent execution structure
        if (result.intermediate_steps) {
            result.intermediate_steps.forEach((step: any) => {
                if (step.tool === 'knowledge_base_search') {
                    sources.push('Knowledge Base');
                } else if (step.tool === 'mongodb_reader') {
                    sources.push('Database');
                }
            });
        }

        return [...new Set(sources)]; // Remove duplicates
    }

    /**
     * Enhanced query processing with knowledge base integration for multiagent coordination
     */
    async processQueryWithKnowledgeContext(query: AgentQuery): Promise<AgentResponse> {
        const startTime = Date.now();
        
        try {
            loggingService.info('Knowledge-enhanced agent query initiated', { value:  { 
                userId: query.userId,
                query: query.query,
                hasContext: !!query.context,
                agentType: process.env.AGENT_TYPE || 'standard'
             } });

            // Use Modular RAG for enhanced knowledge retrieval
            const { modularRAGOrchestrator } = await import('../rag');
            
            // Build RAG context from query context
            const ragContext: any = {
                userId: query.userId,
                conversationId: query.context?.conversationId,
                projectId: query.context?.projectId,
                recentMessages: query.context?.previousMessages || [],
            };

            // Execute RAG with adaptive pattern for efficiency
            const ragResult = await modularRAGOrchestrator.execute({
                query: query.query,
                context: ragContext,
                preferredPattern: 'adaptive', // Use adaptive for agent queries
            });

            // Format knowledge context from RAG result
            let knowledgeContext = '';
            if (ragResult.success && ragResult.documents.length > 0) {
                knowledgeContext = `Knowledge Base Context:\n`;
                ragResult.documents.slice(0, 3).forEach((doc, idx) => {
                    knowledgeContext += `${idx + 1}. ${doc.pageContent.substring(0, 300)}...\n`;
                });
                knowledgeContext += `\nSources: ${ragResult.sources.join(', ')}`;
            } else {
                knowledgeContext = 'No specific knowledge base context found.';
            }

            // Enhance the query with knowledge context
            const enhancedQuery: AgentQuery = {
                ...query,
                context: {
                    ...query.context,
                    knowledgeBaseContext: knowledgeContext,
                    systemCapabilities: [
                        'cost_optimization',
                        'usage_analytics', 
                        'workflow_management',
                        'security_monitoring',
                        'user_management',
                        'webhook_delivery',
                        'training_datasets',
                        'comprehensive_logging'
                    ],
                    availableAgentTypes: ['master', 'optimizer', 'analyst', 'scraper', 'ux']
                }
            };

            // Process with enhanced context
            const response = await this.query(enhancedQuery);

            const duration = Date.now() - startTime;

            loggingService.info('Knowledge-enhanced agent query completed', { value:  { 
                userId: query.userId,
                success: response.success,
                duration,
                hasKnowledgeContext: !!knowledgeContext,
                documentsRetrieved: ragResult.documents.length,
                ragPattern: ragResult.metadata.pattern,
                agentType: process.env.AGENT_TYPE || 'standard'
             } });

            // Log business event
            loggingService.logBusiness({
                event: 'knowledge_enhanced_agent_query',
                category: 'multiagent_coordination',
                value: duration,
                metadata: {
                    userId: query.userId,
                    success: response.success,
                    agentType: process.env.AGENT_TYPE || 'standard',
                    hasKnowledgeContext: !!knowledgeContext
                }
            });

            return {
                ...response,
                metadata: {
                    ...response.metadata,
                    knowledgeEnhanced: true,
                    knowledgeContextLength: knowledgeContext?.length || 0,
                    executionTime: duration
                }
            };

        } catch (error: any) {
            const duration = Date.now() - startTime;
            
            loggingService.error('Knowledge-enhanced agent query failed', {
                userId: query.userId,
                query: query.query,
                error: error.message,
                stack: error.stack,
                duration,
                agentType: process.env.AGENT_TYPE || 'standard'
            });

            return {
                success: false,
                error: `Knowledge-enhanced processing failed: ${error.message}`,
                metadata: {
                    errorType: 'knowledge_enhancement_error',
                    executionTime: duration
                }
            };
        }
    }

    /**
     * Get agent-specific knowledge context
     */
    async getAgentKnowledgeContext(agentType: string, topic?: string): Promise<string> {
        try {
            const knowledgeBaseTool = new KnowledgeBaseTool();
            
            // Build agent-specific query
            let query = `${agentType} agent capabilities and responsibilities`;
            if (topic) {
                query += ` related to ${topic}`;
            }

            const context = await knowledgeBaseTool._call(query);
            
            loggingService.info('Agent knowledge context retrieved', { value:  { 
                agentType,
                topic,
                contextLength: context.length
             } });

            return context;

        } catch (error: any) {
            loggingService.error('Failed to get agent knowledge context', {
                agentType,
                topic,
                error: error.message
            });
            
            return `Error retrieving knowledge context for ${agentType} agent: ${error.message}`;
        }
    }

    /**
     * Coordinate with other agents using knowledge base context
     */
    async coordinateWithAgents(
        primaryQuery: string,
        requiredAgentTypes: string[],
        userId: string
    ): Promise<{
        coordinationPlan: string;
        agentContexts: { [agentType: string]: string };
        recommendations: string[];
    }> {
        try {
            loggingService.info('Multi-agent coordination initiated', { value:  { 
                userId,
                primaryQuery,
                requiredAgentTypes,
                agentCount: requiredAgentTypes.length
             } });

            // Get knowledge context for each required agent type
            const agentContexts: { [agentType: string]: string } = {};
            
            for (const agentType of requiredAgentTypes) {
                agentContexts[agentType] = await this.getAgentKnowledgeContext(agentType, primaryQuery);
            }

            // Generate coordination plan based on knowledge
            const knowledgeBaseTool = new KnowledgeBaseTool();
            const coordinationContext = await knowledgeBaseTool._call(
                `multi-agent coordination patterns and workflow management for: ${primaryQuery}`
            );

            // Generate recommendations
            const recommendations = this.generateCoordinationRecommendations(
                primaryQuery,
                requiredAgentTypes,
                coordinationContext
            );

            loggingService.info('Multi-agent coordination completed', {
                userId,
                primaryQuery,
                agentTypesProcessed: Object.keys(agentContexts).length,
                recommendationsCount: recommendations.length
            });

            return {
                coordinationPlan: coordinationContext,
                agentContexts,
                recommendations
            };

        } catch (error: any) {
            loggingService.error('Multi-agent coordination failed', {
                userId,
                primaryQuery,
                requiredAgentTypes,
                error: error.message,
                stack: error.stack
            });

            throw new Error(`Multi-agent coordination failed: ${error.message}`);
        }
    }

    /**
     * Generate coordination recommendations based on query and agent types
     */
    private generateCoordinationRecommendations(
        query: string,
        agentTypes: string[],
        coordinationContext: string
    ): string[] {
        const recommendations: string[] = [];
        const queryLower = query.toLowerCase();

        // Analyze query for specific coordination patterns
        if (queryLower.includes('cost') || queryLower.includes('optimization')) {
            recommendations.push('Coordinate optimizer and analyst agents for comprehensive cost analysis');
        }

        if (queryLower.includes('data') || queryLower.includes('scraping')) {
            recommendations.push('Use scraper agent to gather data, then analyst agent to process insights');
        }

        if (queryLower.includes('user') || queryLower.includes('interface')) {
            recommendations.push('Involve UX agent for user experience considerations');
        }

        if (queryLower.includes('workflow') || queryLower.includes('process')) {
            recommendations.push('Leverage workflow management capabilities for automated coordination');
        }

        if (agentTypes.includes('master')) {
            recommendations.push('Master agent should orchestrate and validate all agent responses');
        }

        // Add general coordination recommendations
        recommendations.push('Use knowledge base context to ensure consistent responses across agents');
        recommendations.push('Implement proper error handling and fallback mechanisms');
        recommendations.push('Log all agent interactions for observability and debugging');

        return recommendations;
    }

    /**
     * Process query using multi-LLM orchestration pipeline
     * Stage 1: Fast LLM analyzes query intent
     * Stage 2: Smart LLM selects best tools
     * Stage 3: Tools are executed
     * Stage 4: Quality LLM generates final response
     */
    async queryWithMultiLlm(queryData: AgentQuery): Promise<AgentResponse> {
        const startTime = Date.now();
        this.metrics.totalRequests++;

        try {
            loggingService.info('üöÄ Processing query with multi-LLM orchestration', {
                userId: queryData.userId,
                query: queryData.query.substring(0, 100)
            });

            if (!this.initialized) {
                await this.initialize();
            }

            // Dynamically add Vercel tools if user has a Vercel connection
            await this.addVercelToolsIfConnected(queryData.userId);

            // Get all available tools with descriptions
            const availableTools = this.getAllToolsWithDescriptions();

            // Create tool executor function
            const toolExecutor = async (toolName: string, params?: Record<string, any>) => {
                try {
                    const tool = this.getToolInstance(toolName);
                    const input = params ? JSON.stringify(params) : queryData.query;
                    return await tool.invoke({ input });
                } catch (error: any) {
                    loggingService.error(`Tool execution failed: ${toolName}`, {
                        error: error.message
                    });
                    throw error;
                }
            };

            // Build user context
            const userContext = this.buildUserContextCached(queryData);

            // Execute multi-LLM orchestration pipeline
            const orchestrationResult = await multiLlmOrchestratorService.orchestrate(
                queryData.query,
                availableTools,
                toolExecutor,
                userContext
            );

            const executionTime = Date.now() - startTime;

            // Update performance metrics
            this.updatePerformanceMetrics(executionTime);

            const response: AgentResponse = {
                success: true,
                response: orchestrationResult.finalResponse,
                metadata: {
                    executionTime,
                    sources: orchestrationResult.toolSelection.selectedTools.map(t => t.name),
                    fromCache: false
                },
                thinking: {
                    title: `Query Analysis: ${orchestrationResult.analysis.intent}`,
                    summary: `Used ${orchestrationResult.toolSelection.selectedTools.length} tools with ${(orchestrationResult.confidence * 100).toFixed(1)}% confidence`,
                    steps: orchestrationResult.toolSelection.selectedTools.map((tool, idx) => ({
                        step: idx + 1,
                        description: `Execute ${tool.name}`,
                        reasoning: tool.reason,
                        outcome: `Tool executed with priority ${tool.priority}`
                    }))
                }
            };

            loggingService.info('‚úÖ Multi-LLM query processing complete', {
                userId: queryData.userId,
                executionTime,
                toolsUsed: orchestrationResult.toolSelection.selectedTools.length,
                confidence: orchestrationResult.confidence
            });

            return response;

        } catch (error: any) {
            loggingService.error('Multi-LLM query processing failed', {
                error: error.message,
                userId: queryData.userId
            });

            return {
                success: false,
                error: error.message,
                response: 'Failed to process your query with multi-LLM orchestration. Please try again.',
                metadata: {
                    executionTime: Date.now() - startTime,
                    errorType: 'multi_llm_error'
                }
            };
        }
    }

    /**
     * Get all tools with descriptions for multi-LLM orchestrator
     */
    private getAllToolsWithDescriptions(): Array<{ name: string; description: string }> {
        const toolDescriptions: { [key: string]: string } = {
            'knowledge_base_search': 'Search the knowledge base for documentation, guides, and best practices about CostKatana features',
            'mongodb_reader': 'Read and query data from MongoDB database for analytics and reporting',
            'project_manager': 'Manage projects, create new projects, and handle project-related operations',
            'model_selector': 'Select and recommend the best AI models based on cost and performance criteria',
            'analytics_manager': 'Analyze usage patterns, costs, tokens, and generate analytics reports',
            'optimization_manager': 'Provide cost optimization recommendations and strategies',
            'web_search': 'Search the web for external information and current data',
            'vercel_list_projects': 'List all Vercel projects for the connected account',
            'vercel_get_project': 'Get detailed information about a specific Vercel project',
            'vercel_list_deployments': 'List all deployments for a specific Vercel project',
            'vercel_get_deployment': 'Get detailed information about a specific deployment',
            'vercel_list_domains': 'List all domains configured for a Vercel project',
            'vercel_list_env_vars': 'List all environment variables for a Vercel project',
            'vercel_trigger_deployment': 'Trigger a new deployment for a Vercel project',
            'vercel_rollback_deployment': 'Rollback a Vercel project to a previous deployment'
        };

        return Object.entries(toolDescriptions).map(([name, description]) => ({
            name,
            description
        }));
    }

    /**
     * Dynamically add Vercel tools if user has a Vercel connection
     */
    private async addVercelToolsIfConnected(userId: string): Promise<void> {
        try {
            // Check if user has a Vercel connection
            const vercelConnection = await VercelConnection.findOne({
                userId,
                isActive: true
            });

            if (!vercelConnection) {
                return; // No Vercel connection, skip adding tools
            }

            // Check if Vercel tools are already registered
            if (this.toolFactories.has('vercel_list_projects')) {
                return; // Already registered
            }

            loggingService.info('üîå Adding Vercel tools for user', { userId });

            // Create Vercel tools
            const vercelTools = VercelToolsService.createVercelTools(vercelConnection._id.toString());

            // Register each tool
            for (const tool of vercelTools) {
                this.toolFactories.set(tool.name, () => tool);
            }

            // Clear the tools cache to force reload
            this.tools = [];

            loggingService.info('‚úÖ Vercel tools added successfully', {
                userId,
                toolCount: vercelTools.length,
                tools: vercelTools.map(t => t.name)
            });
        } catch (error: any) {
            loggingService.warn('‚ö†Ô∏è Failed to add Vercel tools', {
                userId,
                error: error.message
            });
            // Don't throw - continue without Vercel tools
        }
    }
}

// Singleton instance for the application
export const agentService = new AgentService(); 