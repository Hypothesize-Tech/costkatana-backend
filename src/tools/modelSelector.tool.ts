import { Tool } from "@langchain/core/tools";
import { getModelPricing } from "../data/modelPricing";

interface ModelOperation {
    operation: 'recommend' | 'compare' | 'test' | 'configure' | 'validate';
    useCase?: {
        type: 'api-calls' | 'chatbot' | 'content-generation' | 'data-analysis' | 'code-generation' | 'summarization';
        volume: 'low' | 'medium' | 'high'; // requests per day
        complexity: 'simple' | 'moderate' | 'complex';
        priority: 'cost' | 'quality' | 'speed' | 'balanced';
        requirements?: string[];
    };
    models?: string[];
    testConfig?: {
        samplePrompts?: string[];
        expectedTokens?: number;
        provider?: string;
        model?: string;
    };
}

export class ModelSelectorTool extends Tool {
    name = "model_selector";
    description = `AI model selection and configuration tool that helps users choose the best models for their use case.
    
    This tool can:
    - Recommend optimal models based on use case, budget, and requirements
    - Compare costs and performance across different models
    - Test model integrations and connectivity
    - Configure model settings and parameters
    - Validate model availability and pricing
    
    Input should be a JSON string with:
    {{
        "operation": "recommend|compare|test|configure|validate",
        "useCase": {{
            "type": "api-calls|chatbot|content-generation|data-analysis|code-generation|summarization",
            "volume": "low|medium|high",
            "complexity": "simple|moderate|complex",
            "priority": "cost|quality|speed|balanced",
            "requirements": ["requirement1", "requirement2"]
        }},
        "models": ["model1", "model2"], // for compare operation
        "testConfig": {{
            "samplePrompts": ["test prompt"],
            "expectedTokens": 1000,
            "provider": "anthropic",
            "model": "claude-3-haiku"
        }}
    }}`;

    async _call(input: string): Promise<string> {
        try {
            const operation: ModelOperation = JSON.parse(input);
            
            if (!this.isValidOperation(operation)) {
                return "Invalid operation: Check operation type and required fields.";
            }

            switch (operation.operation) {
                case 'recommend':
                    return await this.recommendModels(operation);
                case 'compare':
                    return await this.compareModels(operation);
                case 'test':
                    return await this.testModel(operation);
                case 'configure':
                    return await this.configureModel(operation);
                case 'validate':
                    return await this.validateModel(operation);
                default:
                    return "Unsupported operation.";
            }

        } catch (error) {
            console.error('Model selection operation failed:', error);
            
            if (error instanceof SyntaxError) {
                return "Invalid JSON input. Please provide a valid operation object.";
            }
            
            return `Model selection error: ${error instanceof Error ? error.message : 'Unknown error'}`;
        }
    }

    private async recommendModels(operation: ModelOperation): Promise<string> {
        try {
            if (!operation.useCase) {
                return "Model recommendation requires use case information.";
            }

            const recommendations = this.generateRecommendations(operation.useCase);
            const costAnalysis = this.analyzeCosts(recommendations, operation.useCase);

            return JSON.stringify({
                success: true,
                useCase: operation.useCase,
                recommendations: recommendations.map(rec => ({
                    ...rec,
                    estimatedMonthlyCost: costAnalysis[rec.model] || 0
                })),
                summary: this.generateRecommendationSummary(recommendations, operation.useCase),
                implementation: this.getImplementationGuidance(recommendations[0])
            }, null, 2);

        } catch (error) {
            return `Failed to recommend models: ${error instanceof Error ? error.message : 'Unknown error'}`;
        }
    }

    private async compareModels(operation: ModelOperation): Promise<string> {
        try {
            if (!operation.models || operation.models.length < 2) {
                return "Model comparison requires at least 2 models.";
            }

            const comparison = operation.models.map(model => {
                const pricing = this.getModelInfo(model);
                const suitability = operation.useCase ? this.assessSuitability(model, operation.useCase) : null;

                return {
                    model,
                    provider: pricing?.provider || 'Unknown',
                    inputCost: pricing?.inputPrice || 0,
                    outputCost: pricing?.outputPrice || 0,
                    contextWindow: pricing?.contextWindow || 0,
                    suitabilityScore: suitability?.score || 0,
                    strengths: suitability?.strengths || [],
                    weaknesses: suitability?.weaknesses || [],
                    estimatedCost: operation.useCase ? 
                        this.estimateUseCost(model, operation.useCase) : 0
                };
            });

            // Sort by best match (considering suitability and cost)
            comparison.sort((a, b) => {
                if (operation.useCase?.priority === 'cost') {
                    return a.estimatedCost - b.estimatedCost;
                }
                return b.suitabilityScore - a.suitabilityScore;
            });

            return JSON.stringify({
                success: true,
                comparison,
                recommendation: comparison[0],
                savings: comparison.length > 1 ? 
                    ((comparison[comparison.length - 1].estimatedCost - comparison[0].estimatedCost) / comparison[comparison.length - 1].estimatedCost * 100).toFixed(1) + '% potential savings' : null
            }, null, 2);

        } catch (error) {
            return `Failed to compare models: ${error instanceof Error ? error.message : 'Unknown error'}`;
        }
    }

    private async testModel(operation: ModelOperation): Promise<string> {
        try {
            if (!operation.testConfig) {
                return "Model testing requires test configuration.";
            }

            // Simulate model testing (in real implementation, this would make actual API calls)
            const testResults = {
                provider: operation.testConfig.provider || 'anthropic',
                model: operation.testConfig.model || 'claude-3-haiku',
                connectivity: 'success',
                responseTime: Math.floor(Math.random() * 2000) + 500, // Simulated
                tokenUsage: {
                    prompt: operation.testConfig.expectedTokens || 100,
                    completion: Math.floor((operation.testConfig.expectedTokens || 100) * 0.8)
                },
                cost: 0.0025, // Simulated
                qualityScore: Math.floor(Math.random() * 30) + 70, // 70-100
                sampleResponse: "Test response generated successfully. The model is working correctly and responding within expected parameters."
            };

            const analysis = this.analyzeTestResults(testResults, operation.testConfig);

            return JSON.stringify({
                success: true,
                testResults,
                analysis,
                recommendations: analysis.recommendations,
                nextSteps: [
                    "Test with your actual use case prompts",
                    "Monitor performance in production environment",
                    "Set up cost alerts and budgets",
                    "Configure fallback models if needed"
                ]
            }, null, 2);

        } catch (error) {
            return `Failed to test model: ${error instanceof Error ? error.message : 'Unknown error'}`;
        }
    }

    private async configureModel(operation: ModelOperation): Promise<string> {
        try {
            const config = {
                modelSettings: {
                    temperature: this.getOptimalTemperature(operation.useCase?.type || 'api-calls'),
                    maxTokens: this.getOptimalMaxTokens(operation.useCase?.type || 'api-calls'),
                    topP: 0.9,
                    frequencyPenalty: 0,
                    presencePenalty: 0
                },
                optimizations: {
                    enableCaching: operation.useCase?.volume !== 'low',
                    enableBatching: operation.useCase?.volume === 'high',
                    compressionLevel: operation.useCase?.priority === 'cost' ? 'aggressive' : 'moderate',
                    contextTrimming: operation.useCase?.type === 'chatbot'
                },
                monitoring: {
                    costTracking: true,
                    qualityScoring: operation.useCase?.priority !== 'cost',
                    performanceMetrics: true,
                    errorLogging: true
                }
            };

            return JSON.stringify({
                success: true,
                configuration: config,
                explanation: this.explainConfiguration(config, operation.useCase),
                implementation: {
                    codeExample: this.generateCodeExample(operation.testConfig?.provider || 'anthropic'),
                    environmentVariables: this.getRequiredEnvVars(operation.testConfig?.provider || 'anthropic'),
                    dependencies: this.getRequiredDependencies(operation.testConfig?.provider || 'anthropic')
                }
            }, null, 2);

        } catch (error) {
            return `Failed to configure model: ${error instanceof Error ? error.message : 'Unknown error'}`;
        }
    }

    private async validateModel(operation: ModelOperation): Promise<string> {
        try {
            const model = operation.testConfig?.model || operation.models?.[0];
            if (!model) {
                return "Model validation requires a model name.";
            }

            const validation = {
                modelExists: true, // Would check actual availability
                pricingAvailable: true,
                apiAccess: true, // Would test API connectivity
                regionSupport: true,
                features: {
                    streaming: true,
                    functionCalling: model.includes('gpt') || model.includes('claude'),
                    vision: model.includes('vision') || model.includes('gpt-4'),
                    codeGeneration: model.includes('gpt') || model.includes('claude') || model.includes('codex')
                },
                limits: {
                    rateLimit: '1000 requests/minute',
                    contextWindow: this.getModelInfo(model)?.contextWindow || 4096,
                    maxTokens: 4096
                }
            };

            return JSON.stringify({
                success: true,
                model,
                validation,
                status: 'ready',
                warnings: validation.apiAccess ? [] : ['API access not available in current region'],
                recommendations: [
                    'Test with small requests before full deployment',
                    'Set up monitoring and alerting',
                    'Configure backup models for redundancy'
                ]
            }, null, 2);

        } catch (error) {
            return `Failed to validate model: ${error instanceof Error ? error.message : 'Unknown error'}`;
        }
    }

    private generateRecommendations(useCase: any) {
        // Define model recommendations based on use case
        const modelMap = {
            'api-calls': [
                { model: 'claude-3-haiku-20240307-v1:0', score: 90, reason: 'Excellent for high-volume, cost-effective API calls' },
                { model: 'gpt-3.5-turbo', score: 85, reason: 'Fast and reliable for general API usage' },
                { model: 'claude-3-sonnet-20240229-v1:0', score: 75, reason: 'Better quality but higher cost' }
            ],
            'chatbot': [
                { model: 'claude-3-sonnet-20240229-v1:0', score: 95, reason: 'Superior conversational abilities' },
                { model: 'gpt-4', score: 90, reason: 'Excellent understanding and context retention' },
                { model: 'claude-3-haiku-20240307-v1:0', score: 80, reason: 'Cost-effective for simple conversations' }
            ],
            'content-generation': [
                { model: 'claude-3-opus-20240229-v1:0', score: 95, reason: 'Best for creative and long-form content' },
                { model: 'gpt-4-turbo', score: 90, reason: 'Excellent creativity and coherence' },
                { model: 'claude-3-sonnet-20240229-v1:0', score: 85, reason: 'Good balance of quality and cost' }
            ],
            'data-analysis': [
                { model: 'claude-3-sonnet-20240229-v1:0', score: 90, reason: 'Strong analytical and reasoning capabilities' },
                { model: 'gpt-4', score: 88, reason: 'Excellent for complex data interpretation' },
                { model: 'claude-3-haiku-20240307-v1:0', score: 75, reason: 'Good for simple analysis tasks' }
            ],
            'code-generation': [
                { model: 'claude-3-sonnet-20240229-v1:0', score: 95, reason: 'Excellent code generation and debugging' },
                { model: 'gpt-4', score: 90, reason: 'Strong programming capabilities' },
                { model: 'codex-davinci-002', score: 85, reason: 'Specialized for code generation' }
            ],
            'summarization': [
                { model: 'claude-3-haiku-20240307-v1:0', score: 95, reason: 'Perfect for high-volume summarization' },
                { model: 'gpt-3.5-turbo', score: 88, reason: 'Fast and accurate summaries' },
                { model: 'claude-3-sonnet-20240229-v1:0', score: 80, reason: 'Better for complex documents' }
            ]
        };

        const models = modelMap[useCase.type as keyof typeof modelMap] || modelMap['api-calls'];
        
        // Adjust recommendations based on priority
        return models.map(model => {
            let adjustedScore = model.score;
            
            if (useCase.priority === 'cost' && model.model.includes('haiku')) {
                adjustedScore += 10;
            } else if (useCase.priority === 'quality' && (model.model.includes('opus') || model.model.includes('gpt-4'))) {
                adjustedScore += 10;
            } else if (useCase.priority === 'speed' && (model.model.includes('haiku') || model.model.includes('3.5-turbo'))) {
                adjustedScore += 5;
            }

            return {
                ...model,
                score: Math.min(adjustedScore, 100)
            };
        }).sort((a, b) => b.score - a.score);
    }

    private analyzeCosts(recommendations: any[], useCase: any) {
        const volumeMultiplier = {
            'low': 1000,    // 1k requests/month
            'medium': 10000, // 10k requests/month
            'high': 100000   // 100k requests/month
        };

        const tokenEstimate = {
            'simple': 500,
            'moderate': 1500,
            'complex': 3000
        };

        const monthlyRequests = volumeMultiplier[useCase.volume as keyof typeof volumeMultiplier] || 1000;
        const avgTokens = tokenEstimate[useCase.complexity as keyof typeof tokenEstimate] || 1000;

        const costs: Record<string, number> = {};
        
        recommendations.forEach(rec => {
            const pricing = this.getModelInfo(rec.model);
            if (pricing) {
                const inputCost = (avgTokens * 0.6 * pricing.inputPrice) / 1000000; // Assuming 60% input tokens
                const outputCost = (avgTokens * 0.4 * pricing.outputPrice) / 1000000; // 40% output tokens
                costs[rec.model] = (inputCost + outputCost) * monthlyRequests;
            }
        });

        return costs;
    }

    private getModelInfo(modelName: string) {
        return getModelPricing(modelName);
    }

    private assessSuitability(model: string, useCase: any) {
        // Simplified suitability assessment
        const scores = {
            'claude-3-haiku-20240307-v1:0': { cost: 95, speed: 95, quality: 75 },
            'claude-3-sonnet-20240229-v1:0': { cost: 75, speed: 85, quality: 90 },
            'claude-3-opus-20240229-v1:0': { cost: 40, speed: 70, quality: 98 },
            'gpt-3.5-turbo': { cost: 90, speed: 95, quality: 80 },
            'gpt-4': { cost: 30, speed: 60, quality: 95 }
        };

        const modelScores = scores[model as keyof typeof scores] || { cost: 50, speed: 50, quality: 50 };
        
        let weightedScore = 0;
        const weights = { cost: 0.4, speed: 0.3, quality: 0.3 }; // Default weights
        
        if (useCase.priority === 'cost') {
            weights.cost = 0.6;
            weights.speed = 0.2;
            weights.quality = 0.2;
        } else if (useCase.priority === 'quality') {
            weights.quality = 0.6;
            weights.cost = 0.2;
            weights.speed = 0.2;
        } else if (useCase.priority === 'speed') {
            weights.speed = 0.6;
            weights.cost = 0.2;
            weights.quality = 0.2;
        }

        weightedScore = modelScores.cost * weights.cost + 
                      modelScores.speed * weights.speed + 
                      modelScores.quality * weights.quality;

        return {
            score: Math.round(weightedScore),
            strengths: this.getModelStrengths(model),
            weaknesses: this.getModelWeaknesses(model)
        };
    }

    private getModelStrengths(model: string): string[] {
        const strengths = {
            'claude-3-haiku-20240307-v1:0': ['Very fast responses', 'Lowest cost', 'High throughput'],
            'claude-3-sonnet-20240229-v1:0': ['Balanced performance', 'Good reasoning', 'Reliable'],
            'claude-3-opus-20240229-v1:0': ['Highest quality', 'Complex reasoning', 'Creative tasks'],
            'gpt-3.5-turbo': ['Fast and affordable', 'Wide compatibility', 'Good general performance'],
            'gpt-4': ['Excellent reasoning', 'High accuracy', 'Complex task handling']
        };
        return strengths[model as keyof typeof strengths] || ['General purpose'];
    }

    private getModelWeaknesses(model: string): string[] {
        const weaknesses = {
            'claude-3-haiku-20240307-v1:0': ['Lower quality for complex tasks', 'Limited reasoning'],
            'claude-3-sonnet-20240229-v1:0': ['Higher cost than Haiku', 'Slower than Haiku'],
            'claude-3-opus-20240229-v1:0': ['Highest cost', 'Slowest responses', 'Rate limits'],
            'gpt-3.5-turbo': ['Limited context window', 'Less sophisticated reasoning'],
            'gpt-4': ['High cost', 'Slower responses', 'Rate limits']
        };
        return weaknesses[model as keyof typeof weaknesses] || [];
    }

    private estimateUseCost(model: string, useCase: any): number {
        const pricing = this.getModelInfo(model);
        if (!pricing) return 0;

        const volumeMultiplier = { 'low': 1000, 'medium': 10000, 'high': 100000 };
        const tokenEstimate = { 'simple': 500, 'moderate': 1500, 'complex': 3000 };

        const monthlyRequests = volumeMultiplier[useCase.volume as keyof typeof volumeMultiplier] || 1000;
        const avgTokens = tokenEstimate[useCase.complexity as keyof typeof tokenEstimate] || 1000;

        const inputCost = (avgTokens * 0.6 * pricing.inputPrice) / 1000000;
        const outputCost = (avgTokens * 0.4 * pricing.outputPrice) / 1000000;
        
        return (inputCost + outputCost) * monthlyRequests;
    }

    private generateRecommendationSummary(recommendations: any[], useCase: any): string {
        const top = recommendations[0];
        return `For ${useCase.type} with ${useCase.priority} priority, I recommend ${top.model}. ${top.reason} This should handle ${useCase.volume} volume with ${useCase.complexity} complexity efficiently.`;
    }

    private getImplementationGuidance(recommendation: any) {
        return {
            setup: [
                `Configure ${recommendation.model} in your project`,
                'Set up API keys and authentication',
                'Configure optimal parameters for your use case',
                'Implement error handling and fallbacks'
            ],
            bestPractices: [
                'Start with small test batches',
                'Monitor costs and performance metrics',
                'Implement caching for repeated requests',
                'Set up alerts for budget thresholds'
            ]
        };
    }

    private analyzeTestResults(results: any, _config: any) {
        const analysis = {
            performance: results.responseTime < 1000 ? 'excellent' : results.responseTime < 2000 ? 'good' : 'slow',
            costEfficiency: results.cost < 0.01 ? 'excellent' : results.cost < 0.05 ? 'good' : 'expensive',
            quality: results.qualityScore > 85 ? 'high' : results.qualityScore > 70 ? 'good' : 'needs improvement',
            recommendations: [] as string[]
        };

        if (analysis.performance === 'slow') {
            analysis.recommendations.push('Consider using a faster model like Claude 3 Haiku for better response times');
        }
        if (analysis.costEfficiency === 'expensive') {
            analysis.recommendations.push('Consider optimizing prompts or using a more cost-effective model');
        }
        if (analysis.quality === 'needs improvement') {
            analysis.recommendations.push('Consider using a higher-quality model or refining your prompts');
        }

        return analysis;
    }

    private getOptimalTemperature(type: string): number {
        const temperatures = {
            'api-calls': 0.1,
            'chatbot': 0.7,
            'content-generation': 0.8,
            'data-analysis': 0.1,
            'code-generation': 0.2,
            'summarization': 0.3
        };
        return temperatures[type as keyof typeof temperatures] || 0.5;
    }

    private getOptimalMaxTokens(type: string): number {
        const maxTokens = {
            'api-calls': 1000,
            'chatbot': 2000,
            'content-generation': 4000,
            'data-analysis': 2000,
            'code-generation': 3000,
            'summarization': 500
        };
        return maxTokens[type as keyof typeof maxTokens] || 2000;
    }

    private explainConfiguration(config: any, useCase: any): string {
        return `Configuration optimized for ${useCase?.type || 'general usage'} with ${useCase?.priority || 'balanced'} priority. Temperature set to ${config.modelSettings.temperature} for ${ config.modelSettings.temperature < 0.3 ? 'consistent' : config.modelSettings.temperature > 0.7 ? 'creative' : 'balanced'} responses.`;
    }

    private generateCodeExample(provider: string): string {
        const examples = {
            'anthropic': `import Anthropic from '@anthropic-ai/sdk';

const client = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});

const response = await client.messages.create({
  model: 'claude-3-haiku-20240307',
  max_tokens: 1000,
  temperature: 0.1,
  messages: [{ role: 'user', content: 'Your prompt here' }],
});`,
            'openai': `import OpenAI from 'openai';

const client = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const response = await client.chat.completions.create({
  model: 'gpt-3.5-turbo',
  max_tokens: 1000,
  temperature: 0.1,
  messages: [{ role: 'user', content: 'Your prompt here' }],
});`
        };
        return examples[provider as keyof typeof examples] || examples.anthropic;
    }

    private getRequiredEnvVars(provider: string): string[] {
        const vars = {
            'anthropic': ['ANTHROPIC_API_KEY'],
            'openai': ['OPENAI_API_KEY'],
            'bedrock': ['AWS_ACCESS_KEY_ID', 'AWS_SECRET_ACCESS_KEY', 'AWS_REGION']
        };
        return vars[provider as keyof typeof vars] || ['API_KEY'];
    }

    private getRequiredDependencies(provider: string): string[] {
        const deps = {
            'anthropic': ['@anthropic-ai/sdk'],
            'openai': ['openai'],
            'bedrock': ['@aws-sdk/client-bedrock-runtime']
        };
        return deps[provider as keyof typeof deps] || [];
    }

    private isValidOperation(operation: ModelOperation): boolean {
        if (!operation.operation) return false;
        
        const validOperations = ['recommend', 'compare', 'test', 'configure', 'validate'];
        if (!validOperations.includes(operation.operation)) return false;

        if (operation.operation === 'recommend' && !operation.useCase) return false;
        if (operation.operation === 'compare' && (!operation.models || operation.models.length < 2)) return false;
        if (operation.operation === 'test' && !operation.testConfig) return false;

        return true;
    }
} 